UID,title,authors,abstract,keywords,pdf_url,acm_pdf_url,acm_html_url
3368555.3384450,Defining admissible rewards for high-confidence policy evaluation in batch reinforcement learning,Niranjani Prasad|Barbara Engelhardt|Finale Doshi-Velez,"A key impediment to reinforcement learning (RL) in real applications with limited, batch data is in defining a reward function that reflects what we implicitly know about reasonable behaviour for a task and allows for robust off-policy evaluation. In this work, we develop a method to identify an admissible set of reward functions for policies that (a) do not deviate too far in performance from prior behaviour, and (b) can be evaluated with high confidence, given only a collection of past trajectories. Together, these ensure that we avoid proposing unreasonable policies in high-risk settings. We demonstrate our approach to reward design on synthetic domains as well as in a critical care context, to guide the design of a reward function that consolidates clinical objectives to learn a policy for weaning patients from mechanical ventilation.",Applied computing|Life and medical sciences|Health care information systems|Computing methodologies|Machine learning|Learning paradigms|Reinforcement learning|Sequential decision making|Learning settings|Batch learning,static/pdf/3368555.3384450.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384450,http://dx.doi.org/10.1145/3368555.3384450
3368555.3384454,Variational learning of individual survival distributions,Zidi Xiu|Chenyang Tao|Ricardo Henao,"The abundance of modern health data provides many opportunities for the use of machine learning techniques to build better statistical models to improve clinical decision making. Predicting time-to-event distributions, also known as survival analysis, plays a key role in many clinical applications. We introduce a variational time-to-event prediction model, named Variational Survival Inference (VSI), which builds upon recent advances in distribution learning techniques and deep neural networks. VSI addresses the challenges of non-parametric distribution estimation by (i) relaxing the restrictive modeling assumptions made in classical models, and (ii) efficiently handling the censored observations, i.e., events that occur outside the observation window, all within the variational framework. To validate the effectiveness of our approach, an extensive set of experiments on both synthetic and real-world datasets is carried out, showing improved performance relative to competing solutions.",Applied computing|Life and medical sciences|Health informatics|Computing methodologies|Modeling and simulation|Model development and analysis|Modeling methodologies,static/pdf/3368555.3384454.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384454,http://dx.doi.org/10.1145/3368555.3384454
3368555.3384456,Interpretable subgroup discovery in treatment effect estimation with application to opioid prescribing guidelines,Chirag Nagpal|Dennis Wei|Bhanukiran Vinzamuri|Monica Shekhar|Sara E. Berger|Subhro Das|Kush R. Varshney,"The dearth of prescribing guidelines for physicians is one key driver of the current opioid epidemic in the United States. In this work, we analyze medical and pharmaceutical claims data to draw insights on characteristics of patients who are more prone to adverse outcomes after an initial synthetic opioid prescription. Toward this end, we propose a generative model that allows discovery from observational data of subgroups that demonstrate an enhanced or diminished causal effect due to treatment. Our approach models these sub-populations as a mixture distribution, using sparsity to enhance interpretability, while jointly learning nonlinear predictors of the potential outcomes to better adjust for confounding. The approach leads to human interpretable insights on discovered subgroups, improving the practical utility for decision support.",Applied computing|Life and medical sciences|Health informatics|Mathematics of computing|Probability and statistics|Probabilistic representations|Bayesian networks|Causal networks,static/pdf/3368555.3384456.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384456,http://dx.doi.org/10.1145/3368555.3384456
3368555.3384459,Adverse drug reaction discovery from electronic health records with deep neural networks,Wei Zhang|Zhaobin Kuang|Peggy Peissig|David Page,"Adverse drug reactions (ADRs) are detrimental and unexpected clinical incidents caused by drug intake. The increasing availability of massive quantities of longitudinal event data such as electronic health records (EHRs) has redefined ADR discovery as a big data analytics problem, where data-hungry deep neural networks are especially suitable because of the abundance of the data. To this end, we introduce neural self-controlled case series (NSCCS), a deep learning framework for ADR discovery from EHRs. NSCCS rigorously follows a self-controlled case series design to adjust implicitly and efficiently for individual heterogeneity. In this way, NSCCS is robust to time-invariant confounding issues and thus more capable of identifying associations that reflect the underlying mechanism between various types of drugs and adverse conditions. We apply NSCCS to a large-scale real-world EHR dataset and empirically demonstrate its superior performance with comprehensive experiments on a benchmark ADR discovery task.",Applied computing|Life and medical sciences|Health informatics|Computing methodologies|Machine learning|Machine learning approaches|Neural networks,static/pdf/3368555.3384459.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384459,http://dx.doi.org/10.1145/3368555.3384459
3368555.3384461,CaliForest: calibrated random forest for health data,Yubin Park|Joyce C. Ho,"Real-world predictive models in healthcare should be evaluated in terms of discrimination, the ability to differentiate between high and low risk events, and calibration, or the accuracy of the risk estimates. Unfortunately, calibration is often neglected and only discrimination is analyzed. Calibration is crucial for personalized medicine as they play an increasing role in the decision making process. Since random forest is a popular model for many healthcare applications, we propose CaliForest, a new calibrated random forest. Unlike existing calibration methodologies, CaliForest utilizes the out-of-bag samples to avoid the explicit construction of a calibration set. We evaluated CaliForest on two risk prediction tasks obtained from the publicly-available MIMIC-III database. Evaluation on these binary prediction tasks demonstrates that CaliForest can achieve the same discriminative power as random forest while obtaining a better-calibrated model evaluated across six different metrics. CaliForest will be published on the standard Python software repository and the code will be openly available on Github.",Applied computing|Life and medical sciences|Health informatics|Computing methodologies|Machine learning|Machine learning algorithms|Ensemble methods|Bagging|Machine learning approaches|Classification and regression trees|General and reference|Cross-computing tools and techniques|Empirical studies,static/pdf/3368555.3384461.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384461,http://dx.doi.org/10.1145/3368555.3384461
3368555.3384447,BMM-Net: automatic segmentation of edema in optical coherence tomography based on boundary detection and multi-scale network,Ruru Zhang|Jiawen He|Shenda Shi|Haihong E|Zhonghong Ou|Meina Song,"Retinal effusions and cysts caused by the leakage of damaged macular vessels and choroid neovascularization are symptoms of many ophthalmic diseases. Optical coherence tomography (OCT), which provides clear 10-layer cross-sectional images of the retina, is widely used to screen various ophthalmic diseases. A large number of researchers have carried out relevant studies on deep learning technology to realize the semantic segmentation of lesion areas, such as effusion on OCT images, and achieved good results. However, in this field, problems of the low contrast of the lesion area and unevenness of lesion size limit the accuracy of the deep learning semantic segmentation model. In this paper, we propose a boundary multi-scale multi-task OCT segmentation network (BMM-Net) for these two challenges to segment the retinal edema area, subretinal fluid, and pigment epithelial detachment in OCT images. We propose a boundary extraction module, a multi-scale information perception module, and a classification module to capture accurate position and semantic information and collaboratively extract meaningful features. We train and verify on the AI Challenger competition dataset. The average Dice coefficient of the three lesion areas is 3.058% higher than the most commonly used model in the field of medical image segmentation and reaches 0.8222.",Applied computing|Life and medical sciences|Computational biology|Imaging|Computing methodologies|Artificial intelligence|Computer vision|Computer vision problems|Image segmentation|Computer vision tasks|Biometrics,static/pdf/3368555.3384447.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384447,http://dx.doi.org/10.1145/3368555.3384447
3368555.3384465,Survival cluster analysis,Paidamoyo Chapfuwa|Chunyuan Li|Nikhil Mehta|Lawrence Carin|Ricardo Henao,"Conventional survival analysis approaches estimate risk scores or individualized time-to-event distributions conditioned on covariates. In practice, there is often great population-level phenotypic heterogeneity, resulting from (unknown) subpopulations with diverse risk profiles or survival distributions. As a result, there is an unmet need in survival analysis for identifying subpopulations with distinct risk profiles, while jointly accounting for accurate individualized time-to-event predictions. An approach that addresses this need is likely to improve the characterization of individual outcomes by leveraging regularities in subpopulations, thus accounting for population-level heterogeneity. In this paper, we propose a Bayesian nonparametrics approach that represents observations (subjects) in a clustered latent space, and encourages accurate time-to-event predictions and clusters (subpopulations) with distinct risk profiles. Experiments on real-world datasets show consistent improvements in predictive performance and interpretability relative to existing state-of-the-art survival analysis models.",Computing methodologies|Machine learning|Machine learning algorithms|Machine learning approaches|Learning latent representations,static/pdf/3368555.3384465.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384465,http://dx.doi.org/10.1145/3368555.3384465
3368555.3384458,An adversarial approach for the robust classification of pneumonia from chest radiographs,Joseph D. Janizek|Gabriel Erion|Alex J. DeGrave|Su-In Lee,"While deep learning has shown promise in the domain of disease classification from medical images, models based on state-of-the-art convolutional neural network architectures often exhibit performance loss due to dataset shift. Models trained using data from one hospital system achieve high predictive performance when tested on data from the same hospital, but perform significantly worse when they are tested in different hospital systems. Furthermore, even within a given hospital system, deep learning models have been shown to depend on hospital- and patient-level confounders rather than meaningful pathology to make classifications. In order for these models to be safely deployed, we would like to ensure that they do not use confounding variables to make their classification, and that they will work well even when tested on images from hospitals that were not included in the training data. We attempt to address this problem in the context of pneumonia classification from chest radiographs. We propose an approach based on adversarial optimization, which allows us to learn more robust models that do not depend on confounders. Specifically, we demonstrate improved out-of-hospital generalization performance of a pneumonia classifier by training a model that is invariant to the view position of chest radiographs (anterior-posterior vs. posterior-anterior). Our approach leads to better predictive performance on external hospital data than both a standard baseline and previously proposed methods to handle confounding, and also suggests a method for identifying models that may rely on confounders.",Applied computing|Life and medical sciences|Computing methodologies|Machine learning|Machine learning approaches|Learning latent representations|Neural networks,static/pdf/3368555.3384458.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384458,http://dx.doi.org/10.1145/3368555.3384458
3368555.3384460,Explaining an increase in predicted risk for clinical alerts,Michaela Hardt|Alvin Rajkomar|Gerardo Flores|Andrew Dai|Michael Howell|Greg Corrado|Claire Cui|Moritz Hardt,"Much work aims to explain a model's prediction on a static input. We consider explanations in a temporal setting where a stateful dynamical model produces a sequence of risk estimates given an input at each time step. When the estimated risk increases, the goal of the explanation is to attribute the increase to a few relevant inputs from the past.While our formal setup and techniques are general, we carry out an in-depth case study in a clinical setting. The goal here is to alert a clinician when a patient's risk of deterioration rises. The clinician then has to decide whether to intervene and adjust the treatment. Given a potentially long sequence of new events since she last saw the patient, a concise explanation helps her to quickly triage the alert.We develop methods to lift static attribution techniques to the dynamical setting, where we identify and address challenges specific to dynamics. We then experimentally assess the utility of different explanations of clinical alerts through expert evaluation.",Applied computing|Life and medical sciences|Health informatics,static/pdf/3368555.3384460.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384460,http://dx.doi.org/10.1145/3368555.3384460
3368555.3384462,Fast learning-based registration of sparse 3D clinical images,Kathleen Lewis|Natalia S. Rost|John Guttag|Adrian V. Dalca,"We introduce SparseVM, a method that registers clinical-quality 3D MR scans both faster and more accurately than previously possible. Deformable alignment, or registration, of clinical scans is a fundamental task for many clinical neuroscience studies. However, most registration algorithms are designed for high-resolution research-quality scans. In contrast to research-quality scans, clinical scans are often sparse, missing up to 86% of the slices available in research-quality scans. Existing methods for registering these sparse images are either inaccurate or extremely slow. We present a learning-based registration method, SparseVM, that is more accurate and orders of magnitude faster than the most accurate clinical registration methods. To our knowledge, it is the first method to use deep learning specifically tailored to registering clinical images. We demonstrate our method on a clinically-acquired MRI dataset of stroke patients and on a simulated sparse MRI dataset. Our code is available as part of the VoxelMorph package at http://voxelmorph.mit.edu.",Applied computing|Life and medical sciences,static/pdf/3368555.3384462.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384462,http://dx.doi.org/10.1145/3368555.3384462
3368555.3384466,Multiple instance learning for predicting necrotizing enterocolitis in premature infants using microbiome data,Thomas Hooven|Yun Chao Lin|Ansaf Salleb-Aouissi,"Necrotizing enterocolitis (NEC) is a life-threatening intestinal disease that primarily affects preterm infants during their first weeks after birth. Mortality rates associated with NEC are 15-30%, and surviving infants are susceptible to multiple serious, long-term complications. The disease is sporadic and, with currently available tools, unpredictable. We are creating an early warning system that uses stool microbiome features, combined with clinical and demographic information, to identify infants at high risk of developing NEC. Our approach uses a multiple instance learning, neural network-based system that could be used to generate daily or weekly NEC predictions for premature infants. The approach was selected to effectively utilize sparse and weakly annotated datasets characteristic of stool microbiome analysis. Here we describe initial validation of our system, using clinical and microbiome data from a nested case-control study of 161 preterm infants. We show receiver-operator curve areas above 0.9, with 75% of dominant predictive samples for NEC-affected infants identified at least 24 hours prior to disease onset. Our results pave the way for development of a real-time early warning system for NEC using a limited set of basic clinical and demographic details combined with stool microbiome data.",Applied computing|Life and medical sciences|Health informatics,static/pdf/3368555.3384466.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384466,http://dx.doi.org/10.1145/3368555.3384466
3368555.3384448,Hurtful words: quantifying biases in clinical contextual word embeddings,Haoran Zhang|Amy X. Lu|Mohamed Abdalla|Matthew McDermott|Marzyeh Ghassemi,"In this work, we examine the extent to which embeddings may encode marginalized populations differently, and how this may lead to a perpetuation of biases and worsened performance on clinical tasks. We pretrain deep embedding models (BERT) on medical notes from the MIMIC-III hospital dataset, and quantify potential disparities using two approaches. First, we identify dangerous latent relationships that are captured by the contextual word embeddings using a fill-in-the-blank method with text from real clinical notes and a log probability bias score quantification. Second, we evaluate performance gaps across different definitions of fairness on over 50 downstream clinical prediction tasks that include detection of acute and chronic conditions. We find that classifiers trained from BERT representations exhibit statistically significant differences in performance, often favoring the majority group with regards to gender, language, ethnicity, and insurance status. Finally, we explore shortcomings of using adversarial debiasing to obfuscate subgroup information in contextual word embeddings, and recommend best practices for such deep embedding models in clinical settings.",Applied computing|Life and medical sciences|Health informatics|Computing methodologies|Machine learning,static/pdf/3368555.3384448.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384448,http://dx.doi.org/10.1145/3368555.3384448
3368555.3384449,Disease state prediction from single-cell data using graph attention networks,Neal Ravindra|Arijit Sehanobish|Jenna L. Pappalardo|David A. Hafler|David van Dijk,"Single-cell RNA sequencing (scRNA-seq) has revolutionized bio-logical discovery, providing an unbiased picture of cellular heterogeneity in tissues. While scRNA-seq has been used extensively to provide insight into health and disease, it has not been used for disease prediction or diagnostics. Graph Attention Networks have proven to be versatile for a wide range of tasks by learning from both original features and graph structures. Here we present a graph attention model for predicting disease state from single-cell data on a large dataset of Multiple Sclerosis (MS) patients. MS is a disease of the central nervous system that is difficult to diagnose. We train our model on single-cell data obtained from blood and cerebrospinal fluid (CSF) for a cohort of seven MS patients and six healthy adults (HA), resulting in 66,667 individual cells. We achieve 92% accuracy in predicting MS, outperforming other state-of-the-art methods such as a graph convolutional network, random forest, and multi-layer perceptron. Further, we use the learned graph attention model to get insight into the features (cell types and genes) that are important for this prediction. The graph attention model also allow us to infer a new feature space for the cells that emphasizes the difference between the two conditions. Finally we use the attention weights to learn a new low-dimensional embedding which we visualize with PHATE and UMAP. To the best of our knowledge, this is the first effort to use graph attention, and deep learning in general, to predict disease state from single-cell data. We envision applying this method to single-cell data for other diseases.",Applied computing|Life and medical sciences|Computational biology|Computational transcriptomics|Computing methodologies|Machine learning|Machine learning algorithms|Feature selection|Machine learning approaches|Neural networks,static/pdf/3368555.3384449.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384449,http://dx.doi.org/10.1145/3368555.3384449
3368555.3384453,Using SNOMED to automate clinical concept mapping,Shaun Gupta|Frederik Dieleman|Patrick Long|Orla Doyle|Nadejda Leavitt,"The International Classification of Disease (ICD) is a widely used diagnostic ontology for the classification of health disorders and a valuable resource for healthcare analytics. However, ICD is an evolving ontology and subject to periodic revisions (e.g. ICD-9-CM to ICD-10-CM) resulting in the absence of complete cross-walks between versions. While clinical experts can create custom mappings across ICD versions, this process is both time-consuming and costly. We propose an automated solution that facilitates interoperability without sacrificing accuracy.Our solution leverages the SNOMED-CT ontology whereby medical concepts are organised in a directed acyclic graph. We use this to map ICD-9-CM to ICD-10-CM by associating codes to clinical concepts in the SNOMED graph using a nearest neighbors search in combination with natural language processing. To assess the impact of our method, the performance of a gradient boosted tree (XGBoost) developed to classify patients with Exocrine Pancreatic Insufficiency (EPI) disorder, was compared when using features constructed by our solution versus clinically-driven methods. This dataset comprised of 23, 204 EPI patients and 277, 324 non-EPI patients with data spanning from October 2011 to April 2017. Our algorithm generated clinical predictors with comparable stability across the ICD-9-CM to ICD-10-CM transition point when compared to ICD-9-CM/ICD-10-CM mappings generated by clinical experts. Preliminary modeling results showed highly similar performance for models based on the SNOMED mapping vs clinically defined mapping (71% precision at 20% recall for both models). Overall, the framework does not compromise on accuracy at the individual code level or at the model-level while obviating the need for time-consuming manual mapping.",Computing methodologies|Machine learning|Machine learning algorithms|Feature selection,static/pdf/3368555.3384453.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384453,http://dx.doi.org/10.1145/3368555.3384453
3368555.3384463,MMiDaS-AE: multi-modal missing data aware stacked autoencoder for biomedical abstract screening,Eric W. Lee|Byron C. Wallace|Karla I. Galaviz|Joyce C. Ho,"Systematic review (SR) is an essential process to identify, evaluate, and summarize the findings of all relevant individual studies concerning health-related questions. However, conducting a SR is labor-intensive, as identifying relevant studies is a daunting process that entails multiple researchers screening thousands of articles for relevance. In this paper, we propose MMiDaS-AE, a Multi-modal Missing Data aware Stacked Autoencoder, for semi-automating screening for SRs. We use a multi-modal view that exploits three representations, of: 1) documents, 2) topics, and 3) citation networks. Documents that contain similar words will be nearby in the document embedding space. Models can also exploit the relationship between documents and the associated SR MeSH terms to capture article relevancy. Finally, related works will likely share the same citations, and thus closely related articles would, intuitively, be trained to be close to each other in the embedding space. However, using all three learned representations as features directly result in an unwieldy number of parameters. Thus, motivated by recent work on multi-modal auto-encoders, we adopt a multi-modal stacked autoencoder that can learn a shared representation encoding all three representations in a compressed space. However, in practice one or more of these modalities may be missing for an article (e.g., if we cannot recover citation information). Therefore, we propose to learn to impute the shared representation even when specific inputs are missing. We find this new model significantly improves performance on a dataset consisting of 15 SRs compared to existing approaches.",Applied computing|Life and medical sciences|Health informatics|Information systems|Information retrieval|Retrieval tasks and goals|Clustering and classification,static/pdf/3368555.3384463.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384463,http://dx.doi.org/10.1145/3368555.3384463
3368555.3384468,Hidden stratification causes clinically meaningful failures in machine learning for medical imaging,Luke Oakden-Rayner|Jared Dunnmon|Gustavo Carneiro|Christopher Re,"Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model may still consistently miss a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring hidden stratification effects, and characterize these effects both via synthetic experiments on the CIFAR-100 benchmark dataset and on multiple real-world medical imaging datasets. Using these measurement techniques, we find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20% on clinically important subsets. Finally, we discuss the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging.",Computing methodologies|Machine learning,static/pdf/3368555.3384468.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384468,http://dx.doi.org/10.1145/3368555.3384468
3368555.3384452,Interactive hybrid approach to combine machine and human intelligence for personalized rehabilitation assessment,Min Hun Lee|Daniel P. Siewiorek|Asim Smailagic|Alexandre Bernardino|Sergi Bermúdez i Badia,"Automated assessment of rehabilitation exercises using machine learning has a potential to improve current rehabilitation practices. However, it is challenging to completely replicate therapist's decision making on the assessment of patients with various physical conditions. This paper describes an interactive machine learning approach that iteratively integrates a data-driven model with expert's knowledge to assess the quality of rehabilitation exercises. Among a large set of kinematic features of the exercise motions, our approach identifies the most salient features for assessment using reinforcement learning and generates a user-specific analysis to elicit feature relevance from a therapist for personalized rehabilitation assessment. While accommodating therapist's feedback on feature relevance, our approach can tune a generic assessment model into a personalized model. Specifically, our approach improves performance to predict assessment from 0.8279 to 0.9116 average F1-scores of three upper-limb rehabilitation exercises (p < 0.01). Our work demonstrates that machine learning models with feature selection can generate kinematic feature-based analysis as explanations on predictions of a model to elicit expert's knowledge of assessment, and how machine learning models can augment with expert's knowledge for personalized rehabilitation assessment.",Applied computing|Life and medical sciences|Health care information systems|Human-centered computing|Human computer interaction (HCI)|Interactive systems and tools|Theory of computation|Theory and algorithms for application domains|Machine learning theory|Reinforcement learning|Sequential decision making,static/pdf/3368555.3384452.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384452,http://dx.doi.org/10.1145/3368555.3384452
3368555.3384467,Extracting medical entities from social media,Sanja Scepanovic|Enrique Martin-Lopez|Daniele Quercia|Khan Baykaner,"Accurately extracting medical entities from social media is challenging because people use informal language with different expressions for the same concept, and they also make spelling mistakes. Previous work either focused on specific diseases (e.g., depression) or drugs (e.g., opioids) or, if working with a wide-set of medical entities, only tackled individual and small-scale benchmark datasets (e.g., AskaPatient). In this work, we first demonstrated how to accurately extract a wide variety of medical entities such as symptoms, diseases, and drug names on three benchmark datasets from varied social media sources, and then also validated this approach on a large-scale Reddit dataset.We first implemented a deep-learning method using contextual embeddings that upon two existing benchmark datasets, one containing annotated AskaPatient posts (CADEC) and the other containing annotated tweets (Micromed), outperformed existing state-of-the-art methods. Second, we created an additional benchmark dataset by annotating medical entities in 2K Reddit posts (made publicly available under the name of MedRed) and showed that our method also performs well on this new dataset.Finally, to demonstrate that our method accurately extracts a wide variety of medical entities on a large scale, we applied the model pre-trained on MedRed to half a million Reddit posts. The posts came from disease-specific subreddits so we could categorise them into 18 diseases based on the subreddit. We then trained a machine-learning classifier to predict the post's category solely from the extracted medical entities. The average F1 score across categories was .87. These results open up new cost-effective opportunities for modeling, tracking and even predicting health behavior at scale.",Applied computing|Life and medical sciences|Health informatics|Computing methodologies|Artificial intelligence|Natural language processing,static/pdf/3368555.3384467.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384467,http://dx.doi.org/10.1145/3368555.3384467
3368555.3384451,Population-aware hierarchical bayesian domain adaptation via multi-component invariant learning,Vishwali Mhasawade|Nabeel Abdur Rehman|Rumi Chunara,"While machine learning is rapidly being developed and deployed in health settings such as influenza prediction, there are critical challenges in using data from one environment to predict in another due to variability in features. Even within disease labels there can be differences (e.g. ""fever"" may mean something different reported in a doctor's office versus in an online app). Moreover, models are often built on passive, observational data which contain different distributions of population subgroups (e.g. men or women). Thus, there are two forms of instability between environments in this observational transport problem. We first harness substantive knowledge from health research to conceptualize the underlying causal structure of this problem in a health outcome prediction task. Based on sources of stability in the model and the task, we posit that we can combine environment and population information in a novel population-aware hierarchical Bayesian domain adaptation framework that harnesses multiple invariant components through population attributes when needed. We study the conditions under which invariant learning fails, leading to reliance on the environment-specific attributes. Experimental results for an influenza prediction task on four datasets gathered from different contexts show the model can improve prediction in the case of largely unlabelled target data from a new environment and different constituent population, by harnessing both environment and population invariant information. This work represents a novel, principled way to address a critical challenge by blending domain (health) knowledge and algorithmic innovation. The proposed approach will have significant impact in many social settings wherein who the data comes from and how it was generated, matters.",Computing methodologies|Machine learning,static/pdf/3368555.3384451.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384451,http://dx.doi.org/10.1145/3368555.3384451
3368555.3384464,TASTE: temporal and static tensor factorization for phenotyping electronic health records,Ardavan Afshar|Ioakeim Perros|Haesun Park|Christopher deFilippi|Xiaowei Yan|Walter Stewart|Joyce Ho|Jimeng Sun,"Phenotyping electronic health records (EHR)focuses on defining meaningful patient groups (e.g., heart failure group and diabetes group) and identifying the temporal evolution of patients in those groups. Tensor factorization has been an effective tool for phenotyping. Most of the existing works assume either a static patient representation with aggregate data or only model temporal data. However, real EHR data contain both temporal (e.g., longitudinal clinical visits) and static information (e.g., patient demographics), which are difficult to model simultaneously. In this paper, we propose Temporal And Static TEnsor factorization (TASTE) that jointly models both static and temporal information to extract phenotypes.TASTE combines the PARAFAC2 model with non-negative matrix factorization to model a temporal and a static tensor. To fit the proposed model, we transform the original problem into simpler ones which are optimally solved in an alternating fashion. For each of the sub-problems, our proposed mathematical re-formulations lead to efficient sub-problem solvers. Comprehensive experiments on large EHR data from a heart failure (HF) study confirmed that TASTE is up to 14× faster than several baselines and the resulting phenotypes were confirmed to be clinically meaningful by a cardiologist. Using 60 phenotypes extracted by TASTE, a simple logistic regression can achieve the same level of area under the curve (AUC) for HF prediction compared to a deep learning model using recurrent neural networks (RNN) with 345 features.",Computing methodologies|Machine learning|Learning paradigms|Unsupervised learning|Dimensionality reduction and manifold learning,static/pdf/3368555.3384464.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384464,http://dx.doi.org/10.1145/3368555.3384464
3368555.3384457,Analyzing the role of model uncertainty for electronic health records,Michael W. Dusenberry|Dustin Tran|Edward Choi|Jonas Kemp|Jeremy Nixon|Ghassen Jerfel|Katherine Heller|Andrew M. Dai,"In medicine, both ethical and monetary costs of incorrect predictions can be significant, and the complexity of the problems often necessitates increasingly complex models. Recent work has shown that changing just the random seed is enough for otherwise well-tuned deep neural networks to vary in their individual predicted probabilities. In light of this, we investigate the role of model uncertainty methods in the medical domain. Using RNN ensembles and various Bayesian RNNs, we show that population-level metrics, such as AUC-PR, AUC-ROC, log-likelihood, and calibration error, do not capture model uncertainty. Meanwhile, the presence of significant variability in patient-specific predictions and optimal decisions motivates the need for capturing model uncertainty. Understanding the uncertainty for individual patients is an area with clear clinical impact, such as determining when a model decision is likely to be brittle. We further show that RNNs with only Bayesian embeddings can be a more efficient way to capture model uncertainty compared to ensembles, and we analyze how model uncertainty is impacted across individual input features and patient subgroups.",Applied computing|Life and medical sciences|Computing methodologies|Machine learning|Machine learning approaches|Neural networks|Modeling and simulation|Model development and analysis|Uncertainty quantification,static/pdf/3368555.3384457.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384457,http://dx.doi.org/10.1145/3368555.3384457
3368555.3384455,Deidentification of free-text medical records using pre-trained bidirectional transformers,Alistair E. W. Johnson|Lucas Bulgarelli|Tom J. Pollard,"The ability of caregivers and investigators to share patient data is fundamental to many areas of clinical practice and biomedical research. Prior to sharing, it is often necessary to remove identifiers such as names, contact details, and dates in order to protect patient privacy. Deidentification, the process of removing identifiers, is challenging, however. High-quality annotated data for developing models is scarce; many target identifiers are highly heterogenous (for example, there are uncountable variations of patient names); and in practice anything less than perfect sensitivity may be considered a failure. Consequently, software for adequately deidentifying clinical data is not widely available. As a result patient data is often withheld when sharing would be beneficial, and identifiable patient data is often divulged when a deidentified version would suffice.In recent years, advances in machine learning methods have led to rapid performance improvements in natural language processing tasks, in particular with the advent of large-scale pretrained language models. In this paper we develop and evaluate an approach for deidentification of clinical notes based on a bidirectional transformer model. We propose human interpretable evaluation measures and demonstrate state of the art performance against modern baseline models. Finally, we highlight current challenges in deidentification, including the absence of clear annotation guidelines, lack of portability of models, and paucity of training data. Code to develop our model is open source and simple to install, allowing for broad reuse.",Applied computing|Document management and text processing|Document preparation|Annotation,static/pdf/3368555.3384455.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384455,http://dx.doi.org/10.1145/3368555.3384455
3368555.3384469,"MIMIC-Extract: a data extraction, preprocessing, and representation pipeline for MIMIC-III",Shirly Wang|Matthew B. A. McDermott|Geeticka Chauhan|Marzyeh Ghassemi|Michael C. Hughes|Tristan Naumann,"Machine learning for healthcare researchers face challenges to progress and reproducibility due to a lack of standardized processing frameworks for public datasets. We present MIMIC-Extract, an open source pipeline for transforming the raw electronic health record (EHR) data of critical care patients from the publicly-available MIMIC-III database into data structures that are directly usable in common time-series prediction pipelines. MIMIC-Extract addresses three challenges in making complex EHR data accessible to the broader machine learning community. First, MIMIC-Extract transforms raw vital sign and laboratory measurements into usable hourly time series, performing essential steps such as unit conversion, outlier handling, and aggregation of semantically similar features to reduce missingness and improve robustness. Second, MIMIC-Extract extracts and makes prediction of clinically-relevant targets possible, including outcomes such as mortality and length-of-stay as well as comprehensive hourly intervention signals for ventilators, vasopressors, and fluid therapies. Finally, the pipeline emphasizes reproducibility and extensibility to future research questions. We demonstrate the pipeline's effectiveness by developing several benchmark tasks for outcome and intervention forecasting and assessing the performance of competitive models.",Applied computing|Life and medical sciences|Health care information systems|Health informatics,static/pdf/3368555.3384469.pdf,https://dl.acm.org/doi/pdf/10.1145/3368555.3384469,http://dx.doi.org/10.1145/3368555.3384469
