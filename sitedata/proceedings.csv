UID,title,authors,abstract,slideslive_id,slideslive_active_date,doi_link
P01,Variationally Regularized Graph-based Representation Learning for Electronic Health Records,Weicheng Zhu (New York University) | Narges Razavian (NYU Grossman School of Medicine),"Electronic Health Records (EHR) are high-dimensional data with implicit connections among thousands of medical concepts. These connections, for instance, the co-occurrence of diseases and lab-disease correlations can be informative when only a subset of these variables is documented by the clinician. A feasible approach to improving the representation learning of EHR data is to associate relevant medical concepts and utilize these connections. Existing medical ontologies can be the reference for EHR structures, but they place numerous constraints on the data source. Recent progress on graph neural networks (GNN) enables end-to-end learning of topological structures for non-grid or non-sequential data. However, there are problems to be addressed on how to learn the medical graph adaptively and how to understand the effect of the medical graph on representation learning. In this paper, we propose a variationally regularized encoder-decoder graph network that achieves more robustness in graph structure learning by regularizing node representations. Our model outperforms the existing graph and non-graph based methods in various EHR predictive tasks based on both public data and real-world clinical data. Besides the improvements in empirical experiment performances, we provide an interpretation of the effect of variational regularization compared to standard graph neural network, using singular value analysis.",38954722,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451855
P02,Affinitention Nets: Kernel Perspective on Attention Architectures for Set Classification with Applications to Medical Text and Images,"David Dov, Serge Assaad, Shijing Si, and Rui Wang (Duke University) | Hongteng Xu (Renmin University of China) | Shahar Ziv Kovalsky (UNC at Chapel Hill) | Jonathan Bell and Danielle Elliott Range (Duke University Hospital) | Jonathan Cohen (Kaplan Medical Center) | Ricardo Henao and Lawrence Carin (Duke University)","Set classification is the task of predicting a single label from a set comprising multiple instances. The examples we consider are pathology slides represented by sets of patches and medical text represented by sets of word embeddings. State of the art methods, such as the transformers, typically use attention mechanisms to learn representations of set-data by modeling interactions between instances of the set. These methods, however, have complex heuristic architectures comprising multiple heads and layers. The complexity of attention architectures hampers their training when only a small number of labeled sets is available, as is often the case in medical applications. To address this problem, we present a kernel-based representation learning framework that associates between learning affinity kernels to learning representations from attention architectures. We show that learning a combination of the sum and the product of kernels is equivalent to learning representations from multi-head multi-layer attention architectures. From our framework, we devise a simplified attention architecture which we term \emph{affinitention} (affinity-attention) nets. We demonstrate the application of affinitention nets to the classification of Set-Cifar10 dataset, thyroid malignancy prediction from pathology slides, as well as patient text message-triage. We show that affinitention nets provide competitive results compared to heuristic attention architectures and outperform other competing methods.",38954723,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451856
P03,Privacy-Preserving and Bandwidth-Efficient Federated Learning: An Application to In-Hospital Mortality Prediction,"Raouf Kerkouche (Privatics team, Univ. Grenoble Alpes, Inria, 38000 Grenoble, France) | Gergely Ács (Crysys Lab, BME-HIT) | Claude Castelluccia (Privatics team, Univ. Grenoble Alpes, Inria, 38000 Grenoble, France) | Pierre Genevès (Tyrex team Univ. Grenoble Alpes, CNRS, Inria, Grenoble INP, LIG 38000 Grenoble, France)","Machine Learning, and in particular Federated Machine Learning, opens new perspectives in terms of medical research and patient care. Although Federated Machine Learning improves over centralized Machine Learning in terms of privacy, it does not provide provable privacy guarantees. Furthermore, Federated Machine Learning is quite expensive in term of bandwidth consumption as it requires participant nodes to regularly exchange large updates. This paper proposes a bandwidth-efficient privacy-preserving Federated Learning that provides theoretical privacy guarantees based on Differential Privacy. We experimentally evaluate our proposal for in-hospital mortality prediction using a real dataset, containing Electronic Health Records of about one million patients. Our results suggest that strong and provable patient-level privacy can be enforced at the expense of only a moderate loss of prediction accuracy.",38954724,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451859
P04,Concept-based Model Explanations for Electronic Health Records,"Diana Mincu (Google Research) | Eric Loreaux (Google Health) | Shaobo Hou (DeepMind) | Sebastien Baur, Ivan Protsyuk, and Martin G Seneviratne (Google Health) | Anne Mottram and Nenad Tomasev (DeepMind) | Alan Karthikesalingam (Google Health) | Jessica Schrouff (Google Research)","Recurrent Neural Networks (RNNs) are often used for sequential modeling of adverse outcomes in electronic health records (EHRs) due to their ability to encode past clinical states. These deep, recurrent architectures have displayed increased performance compared to other modeling approaches in a number of tasks, fueling the interest in deploying deep models in clinical settings. One of the key elements in ensuring safe model deployment and building user trust is model explainability. Testing with Concept Activation Vectors (TCAV) has recently been introduced as a way of providing human-understandable explanations by comparing high-level concepts to the network's gradients. While the technique has shown promising results in real-world imaging applications, it has not been applied to structured temporal inputs. To enable an application of TCAV to sequential predictions in the EHR, we propose an extension of the method to time series data. We evaluate the proposed approach on an open EHR benchmark from the intensive care unit, as well as synthetic data where we are able to better isolate individual effects.",38954725,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451858
P05,Trustworthy Machine Learning for Health Care: Scalable Data Valuation with the Shapley Value,"Konstantin D Pandl, Fabian Feiland, Scott Thiebes, and Ali Sunyaev (Karlsruhe Institute of Technology)","Sharing data is critical to generate large data sets required for the training of machine learning models. Trustworthy machine learning requires incentives, guarantees of data quality, and information privacy. Applying recent advancements in data valuation methods for machine learning can help to enable these. In this work, we analyze the suitability of three different data valuation methods for medical image classification tasks, specifically pleural effusion, on an extensive data set of chest x-ray scans. Our results reveal that a heuristic for calculating the Shapley valuation scheme based on a k-nearest neighbor classifier can successfully value large quantities of data instances. We also demonstrate possible applications for incentivizing data sharing, the efficient detection of mislabeled data, and summarizing data sets to exclude private information. Thereby, this work contributes to developing modern data infrastructures for trustworthy machine learning in health care.",38954726,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451861
P06,Temporal Pointwise Convolutional Networks for Length of Stay Prediction in the Intensive Care Unit,Emma Rocheteau and Pietro Liò (University of Cambridge) | Stephanie Hyland (Microsoft Research),"The pressure of ever-increasing patient demand and budget restrictions make hospital bed management a daily challenge for clinical staff. Most critical is the efficient allocation of resource-heavy Intensive Care Unit (ICU) beds to the patients who need life support. Central to solving this problem is knowing for how long the current set of ICU patients are likely to stay in the unit. In this work, we propose a new deep learning model based on the combination of temporal convolution and pointwise (1x1) convolution, to solve the length of stay prediction task on the eICU and MIMIC-IV critical care datasets. The model - which we refer to as Temporal Pointwise Convolution (TPC) - is specifically designed to mitigate common challenges with Electronic Health Records, such as skewness, irregular sampling and missing data. In doing so, we have achieved significant performance benefits of 18-68% (metric and dataset dependent) over the commonly used Long-Short Term Memory (LSTM) network, and the multi-head self-attention network known as the Transformer. By adding mortality prediction as a side-task, we can improve performance further still, resulting in a mean absolute deviation of 1.55 days (eICU) and 2.28 days (MIMIC-IV) on predicting remaining length of stay.",38954727,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451860
P07,Self-supervised Transfer Learning of Physiological Representations from Free-living Wearable Data,"Dimitris Spathis, Ignacio Pozuelo, Soren Brage, Nicholas J. Wareham, and Cecilia Mascolo (University of Cambridge)","Wearable devices such as smartwatches are becoming increasingly popular tools for objectively monitoring physical activity in free-living conditions. To date, research has primarily focused on the purely supervised task of human activity recognition, demonstrating limited success in inferring high-level health outcomes from low-level signals. Here, we present a novel _self-supervised_ representation learning method using activity and heart rate (HR) signals without semantic labels. With a deep neural network, we set HR responses as the _supervisory signal_ for the activity data, leveraging their underlying physiological relationship. In addition, we propose a custom quantile loss function that accounts for the long-tailed HR distribution present in the general population. We evaluate our model in the largest free-living combined-sensing dataset (comprising >280k hours of wrist accelerometer & wearable ECG data). Our contributions are two-fold: i) the pre-training task creates a model that can accurately forecast HR based only on cheap activity sensors, and ii) we leverage the information captured through this task by proposing a simple method to aggregate the learnt latent representations (embeddings) from the window-level to user-level. Notably, we show that the embeddings can generalize in various downstream tasks through transfer learning with linear classifiers, capturing physiologically meaningful, personalized information. For instance, they can be used to predict variables associated with individuals' health, fitness and demographic characteristics (AUC >70), outperforming unsupervised autoencoders and common bio-markers. Overall, we propose the first multimodal self-supervised method for behavioral and physiological data with implications for large-scale health and lifestyle monitoring. <br /><br /><strong>Code:</strong> <a href='https://github.com/sdimi/Step2heart' target='_blank' rel='noopener'>https://github.com/sdimi/Step2heart</a>",38954728,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451863
P08,Generative ODE Modeling with Known Unknowns,"Ori Linial and Neta Ravid (Technion) | Danny Eytan (Technion, Rambam) | Uri Shalit (Technion)","In several crucial applications, domain knowledge is encoded by a system of ordinary differential equations (ODE), often stemming from underlying physical and biological processes. A motivating example is intensive care unit patients: the dynamics of vital physiological functions, such as the cardiovascular system with its associated variables (heart rate, cardiac contractility and output and vascular resistance) can be approximately described by a known system of ODEs. Typically, some of the ODE variables are directly observed (heart rate and blood pressure for example) while some are unobserved (cardiac contractility, output and vascular resistance), and in addition many other variables are observed but not modeled by the ODE, for example body temperature. Importantly, the unobserved ODE variables are ``known-unknowns'': We know they exist and their functional dynamics, but cannot measure them directly, nor do we know the function tying them to all observed measurements. As is often the case in medicine, and specifically the cardiovascular system, estimating these known-unknowns is highly valuable and they serve as targets for therapeutic manipulations. Under this scenario we wish to learn the parameters of the ODE generating each observed time-series, and extrapolate the future of the ODE variables and the observations. We address this task with a variational autoencoder incorporating the known ODE function, called GOKU-net for Generative ODE modeling with Known Unknowns. We first validate our method on videos of single and double pendulums with unknown length or mass; we then apply it to a model of the cardiovascular system. We show that modeling the known-unknowns allows us to successfully discover clinically meaningful unobserved system parameters, leads to much better extrapolation, and enables learning using much smaller training sets.",38954729,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451866
P09,Learning to Predict with Supporting Evidence: Applications to Clinical Risk Prediction,Aniruddh Raghu and John Guttag (Massachusetts Institute of Technology) | Katherine Young (Harvard Medical School) | Eugene Pomerantsev (Massachusetts General Hospital) | Adrian V. Dalca (Harvard Medical School & MIT) | Collin M. Stultz (Massachusetts Institute of Technology),"The impact of machine learning models on healthcare will depend on the degree of trust that healthcare professionals place in the predictions made by these models. In this paper, we present a method to provide people with clinical expertise with domain-relevant evidence about why a prediction should be trusted. We first design a probabilistic model that relates meaningful latent concepts to prediction targets and observed data. Inference of latent variables in this model corresponds to both making a prediction $\textit{and}$ providing supporting evidence for that prediction. We present a two-step process to efficiently approximate inference: (i) estimating model parameters using variational learning, and (ii) approximating $\textit{maximum a posteriori}$ estimation of latent variables in the model using a neural network trained with an objective derived from the probabilistic model. We demonstrate the method on the task of predicting mortality risk for cardiovascular patients. Specifically, using electrocardiogram and tabular data as input, we show that our approach provides appropriate domain-relevant supporting evidence for accurate predictions.",38954730,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451869
P10,VisualCheXbert: Addressing the Discrepancy Between Radiology Report Labels and Image Labels,"Saahil Jain and Akshay Smit (Stanford University) | Steven QH Truong, Chanh DT Nguyen, and Minh-Thanh Huynh (VinBrain) | Mudit Jain (unaffiliated) | Victoria A. Young, Andrew Y. Ng, Matthew P. Lungren, and Pranav Rajpurkar (Stanford University)","Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17). We also find that VisualCheXbert better agrees with radiologists labeling chest X-ray images than do radiologists labeling the corresponding radiology reports by an average F1 score across several medical conditions of between 0.12 (95% CI 0.09, 0.15) and 0.21 (95% CI 0.18, 0.24).",38954731,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451862
P11,CheXtransfer: Performance and Parameter Efficiency of ImageNet Models for Chest X-Ray Interpretation,"Alexander Ke, William Ellsworth, Oishi Banerjee, Andrew Y. Ng, and Pranav Rajpurkar (Stanford University)","Deep learning methods for chest X-ray interpretation typically rely on pretrained models developed for ImageNet. This paradigm assumes that better ImageNet architectures perform better on chest X-ray tasks and that ImageNet-pretrained weights provide a performance boost over random initialization. In this work, we compare the transfer performance and parameter efficiency of 16 popular convolutional architectures on a large chest X-ray dataset (CheXpert) to investigate these assumptions. First, we find no relationship between ImageNet performance and CheXpert performance for both models without pretraining and models with pretraining. Second, we find that, for models without pretraining, the choice of model family influences performance more than size within a family for medical imaging tasks. Third, we observe that ImageNet pretraining yields a statistically significant boost in performance across architectures, with a higher boost for smaller architectures. Fourth, we examine whether ImageNet architectures are unnecessarily large for CheXpert by truncating final blocks from pretrained models, and find that we can make models 3.25x more parameter-efficient on average without a statistically significant drop in performance. Our work contributes new experimental evidence about the relation of ImageNet to chest x-ray interpretation performance.",38954732,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451867
P12,CheXternal: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays and External Clinical Settings,"Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Andrew Y. Ng, and Matthew P. Lungren (Stanford University)","Recent advances in training deep learning models have demonstrated the potential to provide accurate chest X-ray interpretation and increase access to radiology expertise. However, poor generalization due to data distribution shifts in clinical settings is a key barrier to implementation. In this study, we measured the diagnostic performance for 8 different chest X-ray models when applied to (1) smartphone photos of chest X-rays and (2) external datasets without any finetuning. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to test datasets without further tuning. We found that (1) on photos of chest X-rays, all 8 models experienced a statistically significant drop in task performance, but only 3 performed significantly worse than radiologists on average, and (2) on the external set, none of the models performed statistically significantly worse than radiologists, and five models performed statistically significantly better than radiologists. Our results demonstrate that some chest X-ray models, under clinically relevant distribution shifts, were comparable to radiologists while other models were not. Future work should investigate aspects of model training procedures and dataset collection that influence generalization in the presence of data distribution shifts.",38954733,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451876
P13,Enabling Counterfactual Survival Analysis with Balanced Representations,"Paidamoyo Chapfuwa, Serge Assaad, Shuxi Zeng, Michael Pencina, Lawrence Carin, and Ricardo Henao (Duke University)","Balanced representation learning methods have been applied successfully to counterfactual inference from observational data. However, approaches that account for survival outcomes are relatively limited. Survival data are frequently encountered across diverse medical applications, \textit{i.e.}, drug development, risk profiling, and clinical trials, and such data are also relevant in fields like manufacturing (\textit{e.g.}, for equipment monitoring). When the outcome of interest is a time-to-event, special precautions for handling censored events need to be taken, as ignoring censored outcomes may lead to biased estimates. We propose a theoretically grounded unified framework for counterfactual inference applicable to survival outcomes. Further, we formulate a nonparametric hazard ratio metric for evaluating average and individualized treatment effects. Experimental results on real-world and semi-synthetic datasets, the latter of which we introduce, demonstrate that the proposed approach significantly outperforms competitive alternatives in both survival-outcome prediction and treatment-effect estimation.",38954734,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451875
P14,Controlled Molecule Generator for Optimizing Multiple Chemical Properties,Bonggun Shin and Sungsoo Park (Deargen Inc.) | JinYeong Bak (SungKyunKwan University) | Joyce C. Ho (Emory University),"Generating a novel and optimized molecule with desired chemical properties is an essential part of the drug discovery process. Failure to meet one of the required properties can frequently lead to failure in a clinical test which is costly. In addition, optimizing these multiple properties is a challenging task because the optimization of one property is prone to changing other properties. In this paper, we pose this multi-property optimization problem as a sequence translation process and propose a new optimized molecule generator model based on the Transformer with two constraint networks: property prediction and similarity prediction. We further improve the model by incorporating score predictions from these constraint networks in a modified beam search algorithm. The experiments demonstrate that our proposed model outperforms state-of-the-art models by a significant margin for optimizing multiple properties simultaneously.",38954735,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451879
P15,MetaPhys: Few-Shot Adaptation for Non-Contact Physiological Measurement,Xin Liu and Ziheng Jiang (University of Washington) | Josh Fromm (OctoML) | Xuhai Xu and Shwetak Patel (University of Washington) | Daniel McDuff (Microsoft Research),"There are large individual differences in physiological processes, making designing personalized health sensing algorithms challenging. Existing machine learning systems struggle to generalize well to unseen subjects or contexts and can often contain problematic biases. Video-based physiological measurement is not an exception. Therefore, learning personalized or customized models from a small number of unlabeled samples is very attractive as it would allow fast calibrations to improve generalization and help correct biases. In this paper, we present a novel meta-learning approach called MetaPhys for personalized video-based cardiac measurement. Our method uses only 18-seconds of video for customization and works effectively in both supervised and unsupervised manners. We evaluate our proposed approach on two benchmark datasets and demonstrate superior performance in cross-dataset evaluation with substantial reductions (42% to 44%) in errors compared with state-of-the-art approaches. We have also demonstrated our proposed method significantly helps reduce the bias in skin type.",38954736,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451870
P16,Learning to Safely Approve Updates to Machine Learning Algorithms,"Jean Feng (University of California, San Francisco)","Machine learning algorithms in healthcare have the potential to continually learn from real-world data generated during healthcare delivery and adapt to dataset shifts. As such, regulatory bodies like the US FDA have begun discussions on how to autonomously approve modifications to algorithms. Current proposals evaluate algorithmic modifications via hypothesis testing. However, these methods are only able to define and control the online error rate if the data is stationary over time, which is unlikely to hold in practice. In this manuscript, we investigate designing approval policies for modifications to ML algorithms in the presence of distributional shifts. Our key observation is that the approval policy that is most efficient at identifying and approving beneficial modifications varies across different problem settings. So rather than selecting fixed approval policy a priori, we propose learning the best approval policy by searching over a family of approval strategies. We define a family of strategies that range in their level of optimism when approving modifications. This family includes the pessimistic strategy that, in fact, rescinds approval, which is necessary when no version of the ML algorithm performs well. We use the exponentially weighted averaging forecaster (EWAF) to learn the most appropriate strategy and derive tighter regret bounds assuming the distributional shifts are bounded. In simulation studies and empirical analyses, we find that wrapping approval strategies within EWAF algorithm is a simple yet effective strategy that can help protect against distributional shifts without significantly slowing down approval of beneficial modifications.",38954737,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451864
P17,iGOS++: Integrated Gradient Optimized Saliency by Bilateral Perturbations,"Saeed Khorram, Tyler Lawson, and Fuxin Li (Oregon State University)","The black-box nature of the deep networks makes the explanation for ""why"" they make certain predictions extremely challenging. Saliency maps are one of the most widely-used local explanation tools to alleviate this problem. One of the primary approaches for generating saliency maps is by optimizing a mask over the input dimensions so that the output of the network is influenced the most by the masking. However, prior work only studies such influence by removing evidence from the input. In this paper, we present iGOS++, a framework to generate saliency maps that are optimized for altering the output of the black-box system by either removing or preserving only a small fraction of the input. Additionally, we propose to add a bilateral total variation term to the optimization that improves the continuity of the saliency map especially under high resolution and with thin object parts. The evaluation results from comparing iGOS++ against state-of-the-art saliency map methods show significant improvement in locating salient regions that are directly interpretable by humans. We utilized iGOS++ in the task of classifying COVID-19 cases from x-ray images and discovered that sometimes the CNN network is overfitted to the characters printed on the x-ray images when performing classification. Fixing this issue by data cleansing significantly improved the precision and recall of the classifier.",38954738,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451865
P18,Phenotypical Ontology Driven Framework for Multi-Task Learning,"Mohamed Ghalwash, Zijun Yao, Prithwish Chakraborty, james Codella, and Daby Sow (IBM Research)","Despite the large number of patients in Electronic Health Records (EHRs), the subset of usable data for modeling outcomes of specific phenotypes are often imbalanced and of modest size. This can be attributed to the uneven coverage of medical concepts in EHRs. We propose OMTL, an Ontology-driven Multi-Task Learning framework, that is designed to overcome such data limitations.The key contribution of our work is the effective use of knowledge from a predefined well-established medical relationship graph (ontology) to construct a novel deep learning network architecture that mirrors this ontology. This enables common representations to be shared across related phenotypes, and was found to improve the learning performance. The proposed OMTL naturally allows for multi-task learning of different phenotypes on distinct predictive tasks. These phenotypes are tied together by their semantic relationship according to the external medical ontology. Using the publicly available MIMIC-III database, we evaluate OMTL and demonstrate its efficacy on several real patient outcome predictions over state-of-the-art multi-task learning schemes. The results of evaluating the proposed approach on six experiments show improvement in the area under ROC curve by 9\% and by 8\% in the area under precision-recall curve.",38954748,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451881
P19,RNA Alternative Splicing Prediction with Discrete Compositional Energy Network,"Alvin Chan, Anna Korsakova, Yew-Soon Ong, Fernaldo Richtia Winnerdy, Kah Wai Lim, and Anh Tuan Phan (Nanyang Technological University)","A single gene can encode for different protein versions through a process called alternative splicing. Since proteins play major roles in cellular functions, aberrant splicing profiles can result in a variety of diseases, including cancers. Alternative splicing is determined by the gene's primary sequence and other regulatory factors such as RNA-binding protein levels. With these as input, we formulate the prediction of RNA splicing as a regression task and build a new training dataset (CAPD) to benchmark learned models. We propose discrete compositional energy network (DCEN) which leverages the hierarchical relationships between splice sites, junctions and transcripts to approach this task. In the case of alternative splicing prediction, DCEN models mRNA transcript probabilities through its constituent splice junctions' energy values. These transcript probabilities are subsequently mapped to relative abundance values of key nucleotides and trained with ground-truth experimental measurements. Through our experiments on CAPD, we show that DCEN outperforms baselines and ablation variants.",38954739,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451857
P20,Predictive Models for Colorectal Cancer Recurrence Using Multi-modal Healthcare Data,Danliang Ho (National University of Singapore) | Iain Bee Huat Tan (National Cancer Center Singapore) | Mehul Motani (National University of Singapore),"Colorectal cancer recurrence is a major clinical problem - around 30-40% of patients who are treated with curative intent surgery will experience cancer relapse. Proactive prognostication is critical for early detection and treatment of recurrence. However, the common clinical approach to monitoring recurrence through testing for carcinoembryonic antigen (CEA) does not possess a strong prognostic performance. In our paper, we study a series of machine and deep learning architectures that exploit heterogeneous healthcare data to predict colorectal cancer recurrence. In particular, we demonstrate three different approaches to extract and integrate features from multiple modalities including longitudinal as well as tabular clinical data. Our best model employs a hybrid architecture that takes in multi-modal inputs and comprises: 1) a Transformer model carefully modified to extract high-quality features from time-series data, and 2) a Multi-Layered Perceptron (MLP) that learns tabular data features, followed by feature integration and classification for prediction of recurrence. It achieves an AUROC score of 0.95, as well as precision, sensitivity and specificity scores of 0.83, 0.80 and 0.96 respectively, surpassing the performance of all-known published results based on CEA, as well as most commercially available diagnostic assays. Our results could lead to better post-operative management and follow-up of colorectal cancer patients.",38954740,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451868
P21,B-SegNet : Branched-SegMentor Network For Skin Lesion Segmentation,"shreshth saini (indian institute of technology jodhpur) | Jeon Young Seok and Mengling Feng (Saw Swee Hock School of PublicHealth, National University HealthSystem, National University ofSingapore)","Melanoma is the most common form of cancer in the world. Early diagnosis of the disease and an accurate estimation of its size and shape are crucial in preventing its spread to other body parts. Manual segmentation of these lesions by a radiologist however is time consuming and error-prone. It is clinically desirable to have an automatic tool to detect malignant skin lesions from dermoscopic skin images. We propose a novel end-to-end convolution neural network(CNN) for a precise and robust skin lesion localization and segmentation. The proposed network has 3 sub-encoders branching out from the main encoder. The 3 sub-encoders are inspired from Coordinate Convolution, Hourglass, and Octave Convolutional blocks: each sub-encoder summarizes different patterns and yet collectively aims to achieve a precise segmentation. We trained our segmentation model just on the ISIC 2018 dataset. To demonstrate the generalizability of our model, we evaluated our model on the ISIC 2018 and unseen datasets including ISIC 2017 and PH$^2$. Our approach showed an average 5\% improvement in performance over different datasets while having less than half of the number of parameters when compared to other state-of-the-art segmentation models.",38954741,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451873
P22,Modeling Longitudinal Dynamics of Comorbidities,"Basil Maag, Stefan Feuerriegel, and Mathias Kraus (ETH Zurich) | Maytal Saar-Tsechansky (University of Texas at Austin) | Thomas Zueger (1) Inselspital, Bern, University Hospital, University of Bern 2) ETH Zurich)","In medicine, comorbidities refer to the presence of multiple, co-occurring diseases. Due to their co-occurring nature, the course of one comorbidity is often highly dependent on the course of the other disease and, hence, treatments can have significant spill-over effects. Despite the prevalence of comorbidities among patients, a comprehensive statistical framework for modeling the longitudinal dynamics of comorbidities is missing. In this paper, we propose a probabilistic model for analyzing comorbidity dynamics over time in patients. Specifically, we develop a coupled hidden Markov model with a personalized, non-homogeneous transition mechanism, named Comorbidity-HMM. The specification of our Comorbidity-HMM is informed by clinical research: (1) It accounts for different disease states (i. e., acute, stable) in the disease progression by introducing latent states that are of clinical meaning. (2) It models a coupling among the trajectories from comorbidities to capture co-evolution dynamics. (3) It considers between-patient heterogeneity (e. g., risk factors, treatments) in the transition mechanism. Based on our model, we define a spill-over effect that measures the indirect effect of treatments on patient trajectories through coupling (i. e., through comorbidity co-evolution). We evaluated our proposed Comorbidity-HMM based on 675 health trajectories where we investigate the joint progression of diabetes mellitus and chronic liver disease. Compared to alternative models without coupling, we find that our Comorbidity-HMM achieves a superior fit. Further, we quantify the spill-over effect, that is, to what extent diabetes treatments are associated with a change in the chronic liver disease from an acute to a stable disease state. To this end, our model is of direct relevance for both treatment planning and clinical research in the context of comorbidities.",38954742,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451871
P23,T-DPSOM - An Interpretable Clustering Method for Unsupervised Learning of Patient Health States,"Laura Manduchi, Matthias Hüser, Martin Faltys, Julia Vogt, Gunnar Rätsch, and Vincent Fortuin (ETH Zürich)","Generating interpretable visualizations of multivariate time series in the intensive care unit is of great practical importance. Clinicians seek to condense complex clinical observations into intuitively understandable critical illness patterns, like failures of different organ systems. They would greatly benefit from a low-dimensional representation in which the trajectories of the patients' pathology become apparent and relevant health features are highlighted. To this end, we propose to use the latent topological structure of Self-Organizing Maps (SOMs) to achieve an interpretable latent representation of ICU time series and combine it with recent advances in deep clustering. Specifically, we (a) present a novel way to fit SOMs with probabilistic cluster assignments (PSOM), (b) propose a new deep architecture for probabilistic clustering (DPSOM) using a VAE, and (c) extend our architecture to cluster and forecast clinical states in time series (T-DPSOM). We show that our model achieves superior clustering performance compared to state-of-the-art SOM-based clustering methods while maintaining the favorable visualization properties of SOMs. On the eICU data-set, we demonstrate that T-DPSOM provides interpretable visualizations of patient state trajectories and uncertainty estimation. We show that our method rediscovers well-known clinical patient characteristics, such as a dynamic variant of the Acute Physiology And Chronic Health Evaluation (APACHE) score. Moreover, we illustrate how it can disentangle individual organ dysfunctions on disjoint regions of the two-dimensional SOM map.",38954743,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451872
P24,Contextualization and Individualization for Just-in-Time Adaptive Interventions to Reduce Sedentary Behavior,"Matthew Saponaro, Ajith Vemuri, Greg Dominick, and Keith Decker (University of Delaware)","Wearable technology opens opportunities to reduce sedentary behavior; however, commercially available devices do not provide tailored coaching strategies. Just-In-Time Adaptive Interventions (JITAI) provide such a framework; however most JITAI are conceptual to date. We conduct a study to evaluate just-in-time nudges in free-living conditions in terms of receptiveness and nudge impact. We first quantify baseline behavioral patterns in context using features such as location and step count, and assess differences in individual responses. We show there is a strong inverse relationship between average daily step counts and time spent being sedentary indicating that steps are steadily taken throughout the day, rather than in large bursts. Interestingly, the effect of nudges delivered at the workplace is larger in terms of step count than those delivered at home. We develop Random Forest models to learn nudge receptiveness using both individualized and contextualized data. We show that step count is the least important identifier in nudge receptiveness, while location is the most important. Furthermore, we compare the developed models with a commercially available smart coach using post-hoc analysis. The results show that using the contextualized and individualized information significantly outperforms non-JITAI approaches to determine nudge receptiveness.",38954744,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451874
P25,A Comprehensive EHR Timeseries Pre-training Benchmark,"Matthew McDermott (Massachusetts Institute of Technology) | Bret Nestor (University of Toronto) | Evan Kim (Massachusetts Institute of Technology) | Wancong Zhang (New York University) | Anna Goldenberg (Hospital for Sick Children, University of Toronto, Vector Institute) | Peter Szolovits (MIT) | Marzyeh Ghassemi (University of Toronto | Vector Institute for Artificial Intelligence)","Pre-training (PT) has been used successfully in many areas of machine learning. One area where PT would be extremely impactful is over electronic health record (EHR) data. Successful PT strategies on this modality could improve model performance in data-scarce contexts such as modeling for rare diseases or allowing smaller hospitals to benefit from data from larger health systems. While many PT strategies have been explored in other domains, much less exploration has occurred for EHR data. One reason this may be is the lack of standardized benchmarks suitable for developing and testing PT algorithms. In this work, we establish a PT benchmark dataset for EHR timeseries data, establishing cohorts, a diverse set of fine-tuning tasks, and PT-focused evaluation regimes across two public EHR datasets: MIMIC-III and eICU. This benchmark fills an essential hole in the field by enabling a robust manner of iterating on PT strategies for this modality. To show the value of this benchmark and provide baselines for further research, we also profile two simple PT algorithms: a self-supervised, masked imputation system and a weakly-supervised, multi-task system. We find that PT strategies (in particular weakly-supervised PT methods) can offer significant gains over traditional learning in few-shot settings, especially on tasks with strong class imbalance. Our full benchmark and code are publicly available at <a href='https://github.com/mmcdermott/comprehensive_MTL_EHR' target='_blank' rel='noopener'>https://github.com/mmcdermott/comprehensive_MTL_EHR</a>.",38954745,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451877
P26,An Empirical Framework for Domain Generalization In Clinical Settings,"Haoran Zhang (University of Toronto | Vector Institute) | Natalie Dullerud (University of Toronto, Vector Institute) | Laleh Seyyed-Kalantari (University of Toronto) | Quaid Morris (Memorial Sloan Kettering Cancer Center) | Shalmali Joshi (Harvard University) | Marzyeh Ghassemi (University of Toronto | Vector Institute for Artificial Intelligence)","Clinical machine learning models have been found to significantly degrade in performance on hospitals or regions not seen during training. Recent developments in domain generalization offer a promising solution to this problem, by creating models that learn invariances which hold across environments. In this work, we benchmark the performance of eight domain generalization methods on clinical time series and medical imaging data. We introduce a framework to induce practical confounding and sampling bias to stress-test these methods over existing non-healthcare benchmarks. We find, consistent with prior work, that current domain generalization methods do not achieve significant gains in out-of-distribution performance over empirical risk minimization on real-world medical imaging data. However, we do find a subset of realistic confounding scenarios where significant performance gains are observed. We characterize these scenarios in detail, and recommend best practices for domain generalization in the clinical setting.",38954746,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451878
P27,Influenza-like Symptom Recognition using Mobile Sensing and Graph Neural Networks,"Guimin Dong, Lihua Cai, Debajyoti Datta, Shashwat Kumar, Laura E. Barnes, and Mehdi Boukhechba (University of Virginia)","Early detection of influenza-like symptoms can prevent widespread flu viruses and enable timely treatments, particularly in the post-pandemic era. Mobile sensing leverages an increasingly diverse set of embedded sensors to capture fine-grained information of human behaviors and ambient contexts and can serve as a promising solution for influenza-like symptom recognition. Traditionally, handcrafted and high level features of mobile sensing data are extracted by using handcrafted feature engineering and Convolutional/Recurrent Neural Network respectively. However, in this work, we use graph representation to encode the dynamics of state transitions and internal dependencies in human behaviors, apply graph embeddings to automatically extract the topological and spatial features from graph input and propose an end-to-end Graph Neural Network model with multi-channel mobile sensing input for influenza-like symptom recognition based on people's daily mobility, social interactions, and physical activities. Using data generated from 448 participants, We show that Graph Neural Networks (GNN) with GraphSAGE convolutional layers significantly outperform baseline models with handcrafted features. Furthermore, we use GNN interpretability method to generate insight (important node, graph structure) for the symptom recognition. To the best of our knowledge, this is the first work that applies graph representation and graph neural network on mobile sensing data for graph-based human behaviors modeling.",38954747,2021-04-14T23:59:00.00,https://doi.org/10.1145/3450439.3451880
