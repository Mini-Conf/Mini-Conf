UID,title,authors,abstract,session
P01,Denoising Autoencoders for Learning from Noisy Patient-Reported Data,"Harry Rubin-Falcone* (University of Michigan)|Joyce Lee (University of Michigan)|Jenna Wiens (University of Michigan)","Healthcare datasets often include patient-reported values, such as mood, symptoms, and meals, which can be subject to varying levels of human error. Improving the accuracy of patient-reported data could help in several downstream tasks, such as remote patient monitoring.  In this study, we propose a novel denoising autoencoder (DAE) approach to denoise patient-reported data, drawing inspiration from recent work in computer vision. Our approach is based on the observation that noisy patient-reported data are often collected alongside higher fidelity data collected from wearable sensors. We leverage these auxiliary data to improve the accuracy of the patient-reported data. Our approach combines key ideas from DAEs with co-teaching to iteratively filter and learn from clean patient-reported samples. Applied to the task of recovering carbohydrate values for blood glucose management in diabetes, our approach reduces noise (MSE) in patient-reported carbohydrates from 72<span class=""font-italic"">g<sup>2</sup></span> (95% CI: 54-93) to 18<span class=""font-italic"">g<sup>2</sup></span> (13-25), outperforming the best baseline (33<span class=""font-italic"">g<sup>2</sup></span> (27-43)). Notably, our approach achieves strong performance with only access to patient-reported target values, making it applicable to many settings where ground truth data may be unavailable.",B
P02,Adaptive Weighted Multi-View Clustering,"Shuo Shuo Liu* (Pennsylvania State University)|Lin Lin (Duke University)","Learning multi-view data is an emerging problem in machine learning research, and nonnegative matrix factorization (NMF) is a popular dimensionality-reduction method for integrating information from multiple views. These views often provide not only consensus but also complementary information. However, most multi-view NMF algorithms assign equal weight to each view or tune the weight via line search empirically, which can be infeasible without any prior knowledge of the views or computationally expensive. In this paper, we propose a weighted multi-view NMF (WM-NMF) algorithm.  In particular, we aim to address the critical technical gap, which is to learn both view-specific weight and observation-specific reconstruction weight to quantify each view’s information content. The introduced weighting scheme can alleviate unnecessary views' adverse effects and enlarge the positive effects of the important views by assigning smaller and larger weights, respectively. Experimental results confirm the effectiveness and advantages of the proposed algorithm in terms of achieving better clustering performance and dealing with the noisy data compared to the existing algorithms.",A
P03,Token Imbalance Adaptation for Radiology Report Generation,Yuexin Wu* (University of Memphis)|I-Chan Huang (St. Jude Children's Research Hospital)|Xiaolei Huang (University of Memphis),"Imbalanced token distributions naturally exist in text documents, leading neural language models to overfit on frequent tokens. The token imbalance may dampen the robustness of radiology report generators, as complex medical terms appear less frequently but reflect more medical information. In this study, we demonstrate how current state-of-the-art models fail to generate infrequent tokens on two standard benchmark datasets (IU X-RAY and MIMIC-CXR) of radiology report generation. To solve the challenge, we propose the <span class=""font-weight-bold"">T</span>oken <span class=""font-weight-bold"">Im</span>balance Adapt<span class=""font-weight-bold"">er</span> (<span class=""font-italic"">TIMER</span>), aiming to improve generation robustness on infrequent tokens. The model automatically leverages token imbalance by an unlikelihood loss and dynamically optimizes generation processes to augment infrequent tokens. We compare our approach with multiple state-of-the-art methods on the two benchmarks. Experiments demonstrate the effectiveness of our approach in enhancing model robustness overall and infrequent tokens. Our ablation analysis shows that our reinforcement learning method has a major effect in adapting token imbalance for radiology report generation.",A
P04,Federated Multilingual Models for Medical Transcript Analysis,"Andre Manoel* (Microsoft)|Mirian Del Carmen Hipolito Garcia (Microsoft)|Tal Baumel (Microsoft)|Shize Su (Microsoft)|Jialei Chen (Microsoft)|Robert Sim (Microsoft)|Dan Miller (Airbnb)|Danny Karmon (Google)|Dimitrios Dimitriadis (Amazon)","Federated Learning (FL) is a machine learning approach that allows the model trainer to access more data samples by training across multiple decentralized data sources while enforcing data access constraints. Such trained models can achieve significantly higher performance beyond what can be done when trained on a single data source. In a FL setting, none of the training data is ever transmitted to any central location; i.e. sensitive data remains local and private. These characteristics make FL perfectly suited for applications in healthcare, where a variety of compliance constraints restrict how data may be handled. Despite these apparent benefits in compliance and privacy, certain scenarios such as heterogeneity of the local data distributions pose significant challenges for FL. Such challenges are even more pronounced in the case of a multilingual setting. This paper presents a FL system for pre-training a large-scale multi-lingual model suitable for fine-tuning on downstream tasks such as medical entity tagging. Our work represents one of the first such production-scale systems, capable of training across multiple highly heterogeneous data providers, and achieving levels of accuracy that could not be otherwise achieved by using central training with public data only. We also show that the global model performance can be further improved by a local training step.","B"
P05,Rare Life Event Detection via Mobile Sensing Using Multi-Task Learning,"Arvind Pillai* (Dartmouth College)|Subigya Nepal (Dartmouth College)|Andrew Campbell (Dartmouth College)","Rare life events significantly impact mental health, and their detection in behavioral studies is a crucial step towards health-based interventions. We envision that mobile sensing data can be used to detect these anomalies. However, the human-centered nature of the problem, combined with the infrequency and uniqueness of these events makes it challenging for unsupervised machine learning methods. In this paper, we first investigate granger-causality between life events and human behavior using sensing data. Next, we propose a multi-task framework with an unsupervised autoencoder to capture irregular behavior, and an auxiliary sequence predictor that identifies transitions in workplace performance to contextualize events. We perform experiments using data from a mobile sensing study comprising N=126 information workers from multiple industries, spanning 10106 days with 198 rare events (<2%). Through personalized inference, we detect the exact day of a rare event with an F1 of 0.34, demonstrating that our method outperforms several baselines. Finally, we discuss the implications of our work from the context of real-world deployment.","B"
P06,Virus2Vec: Viral Sequence Classification Using Machine Learning,"Sarwan Ali* (Georgia State University)|Babatunde Bello (Georgia State University)|Prakash Chourasia (Georgia State University)|Ria Thazhe Punathil (Georgia State University)|Pin-Yu Chen (IBM Research)|Imdad Ullah Khan (Lahore University of Management Sciences)|Murray Patterson (Georgia State University)","Understanding the host-specificity of different families of viruses sheds light on the origin of, e.g., SARS-CoV-2, rabies, and other such zoonotic pathogens in humans. It enables epidemiologists, medical professionals, and policymakers to curb existing epidemics and prevent future ones promptly. In the family Coronaviridae (of which SARS-CoV-2 is a member), it is well-known that the spike protein is the point of contact between the virus and the host cell membrane. On the other hand, the two traditional mammalian orders, Carnivora (carnivores) and Chiroptera (bats) are recognized to be responsible for maintaining and spreading the Rabies Lyssavirus (RABV). We propose Virus2Vec, a feature-vector representation for viral (nucleotide or amino acid) sequences that enable vector-space-based machine learning models to identify viral hosts. Virus2Vec generates numerical feature vectors for unaligned sequences, allowing us to forego the computationally expensive sequence alignment step from the pipeline. Virus2Vec leverages the power of both the <span class=""font-italic"">minimizer</span> and position weight matrix (PWM) to generate compact feature vectors. Using several classifiers, we empirically evaluate Virus2Vec on real-world spike sequences of Coronaviridae and rabies virus sequence data to predict the host (identifying the reservoirs of infection). Our results demonstrate that Virus2Vec outperforms the predictive accuracies of baseline and state-of-the-art methods.","A"
P07,A General Framework for Visualizing Embedding Spaces of Neural Survival Analysis Models Based on Angular Information,"George H. Chen* (Carnegie Mellon University)","We propose a general framework for visualizing any intermediate embedding representation used by any neural survival analysis model. Our framework is based on so-called <span class=""font-italic"">anchor directions</span> in an embedding space. We show how to estimate these anchor directions using clustering or, alternatively, using user-supplied ``concepts'' defined by collections of raw inputs (e.g., feature vectors all from female patients could encode the concept ``female''). For tabular data, we present visualization strategies that reveal how anchor directions relate to raw clinical features and to survival time distributions. We then show how these visualization ideas extend to handling raw inputs that are images. Our framework is built on looking at angles between vectors in an embedding space, where there could be ``information loss'' by ignoring magnitude information. We show how this loss results in a ``clumping'' artifact that appears in our visualizations, and how to reduce this information loss in practice.","B"
P08,Towards the Practical Utility of Federated Learning in the Medical Domain,"Hyeonji Hwang* (KAIST)|Seongjun Yang (KRAFTON)|Daeyoung Kim (KAIST)|Radhika Dua (Google Research)|Jong-Yeup Kim(Konyang University)|Eunho Yang (KAIST) |Edward Choi (KAIST)","Federated learning (FL) is an active area of research. One of the most suitable areas for adopting FL is the medical domain, where patient privacy must be respected. Previous research, however, does not provide a practical guide to applying FL in the medical domain. We propose empirical benchmarks and experimental settings for three representative medical datasets with different modalities: longitudinal electronic health records, skin cancer images, and electrocardiogram signals. The likely users of FL such as medical institutions and IT companies can take these benchmarks as guides for adopting FL and minimize their trial and error. For each dataset, each client data is from a different source to preserve real-world heterogeneity. We evaluate six FL algorithms designed for addressing data heterogeneity among clients, and a hybrid algorithm combining the strengths of two representative FL algorithms. Based on experiment results from three modalities, we discover that simple FL algorithms tend to outperform more sophisticated ones, while the hybrid algorithm consistently shows good, if not the best performance. We also find that a frequent global model update leads to better performance under a fixed training iteration budget. As the number of participating clients increases, higher cost is incurred due to increased IT administrators and GPUs, but the performance consistently increases. We expect future users will refer to these empirical benchmarks to design the FL experiments in the medical domain considering their clinical tasks and obtain stronger performance with lower costs.","A"
P09,Large-Scale Study of Temporal Shift in Health Insurance Claims,"Christina X Ji (MIT CSAIL and IMES)|Ahmed Alaa (UC Berkeley and UCSF)|David Sontag (MIT CSAIL and IMES)","Most machine learning models for predicting clinical outcomes are developed using historical data. Yet, even if these models are deployed in the near future, dataset shift over time may result in less than ideal performance. To capture this phenomenon, we consider a task---that is, an outcome to be predicted at a particular time point---to be non-stationary if a historical model is no longer optimal for predicting that outcome. We build an algorithm to test for temporal shift either at the population level or within a discovered sub-population. Then, we construct a meta-algorithm to perform a retrospective scan for temporal shift on a large collection of tasks. Our algorithms enable us to perform the first comprehensive evaluation of temporal shift in healthcare to our knowledge. We create 1,010 tasks by evaluating 242 healthcare outcomes for temporal shift from 2015 to 2020 on a health insurance claims dataset. 9.7% of the tasks show temporal shifts at the population level, and 93.0% have some sub-population affected by shifts. We dive into case studies to understand the clinical implications. Our analysis highlights the widespread prevalence of temporal shifts in healthcare.","A"
P10,Semantic match: Debugging feature attribution methods in XAI for healthcare,"Giovanni Cinà* (Amsterdam University Medical Center)|Tabea E. Röber (University of Amsterdam)|Rob Goedhart (University of Amsterdam)|Ş. İlker  Birbil (University of Amsterdam)","The recent spike in certified Artificial Intelligence tools for healthcare has renewed the debate around adoption of this technology. One thread of such debate concerns Explainable AI and its promise to render AI devices more transparent and trustworthy. A few voices active in the medical AI space have expressed concerns on the reliability of Explainable AI techniques and especially feature attribution methods, questioning their use and inclusion in guidelines and standards. We characterize the problem as a lack of semantic match between explanations and human understanding. To understand when feature importance can be used reliably, we introduce a distinction between feature importance of low- and high-level features. We argue that for data types where low-level features come endowed with a clear semantics, such as tabular data like Electronic Health Records, semantic match can be obtained, and thus feature attribution methods can still be employed in a meaningful and useful way. For high-level features, we sketch a procedure to test whether semantic match has been achieved.","B"
P11,Modeling Multivariate Biosignals With Graph Neural Networks and Structured State Space Models,"Siyi Tang* (Stanford University)|Jared A. Dunnmon (Stanford University)|Liangqiong Qu (University of Hong Kong)|Khaled K. Saab (Stanford University)|Tina Baykaner (Stanford University)|Christopher Lee-Messer (Stanford University)|Daniel L. Rubin (Stanford University)","Multivariate biosignals are prevalent in many medical domains, such as electroencephalography, polysomnography, and electrocardiography. Modeling spatiotemporal dependencies in multivariate biosignals is challenging due to (1) long-range temporal dependencies and (2) complex spatial correlations between the electrodes. To address these challenges, we propose representing multivariate biosignals as time-dependent graphs and introduce GRAPHS4MER, a general graph neural network (GNN) architecture that improves performance on biosignal classification tasks by modeling spatiotemporal dependencies in biosignals. Specifically, (1) we leverage the Structured State Space architecture, a state-of-the-art deep sequence model, to capture long-range temporal dependencies in biosignals and (2) we propose a graph structure learning layer in GRAPHS4MER to learn dynamically evolving graph structures in the data.  We evaluate our proposed model on three distinct biosignal classification tasks and show that GRAPHS4MER consistently improves over existing models, including (1) seizure detection from electroencephalographic signals, outperforming a previous GNN with self-supervised pre-training by 3.1 points in AUROC; (2) sleep staging from polysomnographic signals, a 4.1 points improvement in macro-F1 score compared to existing sleep staging models; and (3) 12-lead electrocardiogram classification, outperforming previous state-of-the-art models by 2.7 points in macro-F1 score.","B"
P12,Neural Fine-Gray: Monotonic neural networks for competing risks,"Vincent Jeanselme* (University of Cambridge)|Chang Ho Yoon (University of Oxford)|Brian Tom (University of Cambridge)|Jessica Barrett (University of Cambridge)","Time-to-event modelling, known as survival analysis, differs from standard regression as it addresses <span class=""font-italic"">censoring</span> in patients who do not experience the event of interest. Despite competitive performances in tackling this problem, machine learning methods often ignore other <span class=""font-italic"">competing risks</span> that preclude the event of interest. This practice biases the survival estimation. Extensions to address this challenge often rely on parametric assumptions or numerical estimations leading to sub-optimal survival approximations. This paper leverages constrained monotonic neural networks to model each competing survival distribution. This modelling choice ensures the exact likelihood maximisation at a reduced computational cost by using automatic differentiation. The effectiveness of the solution is demonstrated on one synthetic and three medical datasets. Finally, we discuss the implications of considering competing risks when developing risk scores for medical practice.","A"
P13,Multi-modal Pre-training for Medical Vision-language Understanding and Generation: An Empirical Study with A New Benchmark,"Li Xu* (Hong Kong Polytechnic University)|Bo Liu (Hong Kong Polytechnic University)|Ameer Hamza Khan (Hong Kong Polytechnic University)|Lu Fan (Hong Kong Polytechnic University)|Xiao-Ming Wu (Hong Kong Polytechnic University)","With the availability of large-scale, comprehensive, and general-purpose vision-language (VL) datasets such as MSCOCO, vision-language pre-training (VLP) has become an active area of research and proven to be effective for various VL tasks such as visual-question answering. However, studies on VLP in the medical domain have so far been scanty. To provide a comprehensive perspective on VLP for medical VL tasks, we conduct a thorough experimental analysis to study key factors that may affect the performance of VLP with a unified vision-language Transformer. To allow making sound and quick pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality, multi-modality radiographic dataset containing 18,434 image-caption pairs collected from an open-access online database MedPix. RGC can be used as a pre-training dataset or a new benchmark for medical report generation and medical image-text retrieval. By utilizing RGC and other available datasets for pre-training, we develop several key insights that can guide future medical VLP research and new strong baselines for various medical VL tasks.","A"
P14,SRDA: Mobile Sensing based Fluid Overload Detection for End Stage Kidney Disease Patients using Sensor Relation Dual Autoencoder,"Mingyue Tang (University of Virginia)|Jiechao Gao* (University of Virginia)|Guimin Dong (Amazon)|Carl Yang (Emory University)|Brad Campbell (University of Virginia)|Brendan Bowman (University of Virginia)|Jamie Marie Zoellner (University of Virginia)|Emaad Abdel-Rahman (University of Virginia)|Mehdi Boukhechba (The Janssen Pharmaceutical Companies of Johnson & Johnson)","Chronic kidney disease (CKD) is a life-threatening and prevalent disease. CKD patients, especially end-stage kidney disease (ESKD) patients on hemodialysis, suffer from kidney failures and are unable to remove excessive fluid, causing fluid overload and multiple morbidities including death. Current solutions for fluid overtake monitoring such as ultrasonography and biomarkers assessment are cumbersome, discontinuous, and can only be performed in the clinic. In this paper, we propose SRDA, a latent graph learning powered fluid overload detection system based on <span style=""text-decoration:underline"">S</span>ensor <span style=""text-decoration:underline"">R</span>elation <span style=""text-decoration:underline"">D</span>ual <span style=""text-decoration:underline"">A</span>utoencoder to detect excessive fluid consumption of EKSD patients based on passively collected bio-behavioral data from smartwatch sensors. Experiments using real-world mobile sensing data indicate that SRDA outperforms the state-of-the-art baselines in both F1 score and recall, and demonstrate the potential of ubiquitous sensing for ESKD fluid intake management.","B"
P15,Who Controlled the Evidence? Question Answering for Disclosure Information Retrieval,"Hardy* (Universitas Mikroskil)|Derek Ruths (McGill University)|Nicholas B King (McGill University)","Conflict of interest (COI) disclosure statements provide rich information to support transparency and reduce bias in research. We introduce a novel task to identify relationships between sponsoring entities and the research studies they sponsor from the disclosure statement. This task is challenging due to the complexity of recognizing all potential relationship patterns and the hierarchical nature of identifying entities first and then extracting their relationships to the study. To overcome these challenges, in this paper, we also constructed a new annotated dataset and proposed a Question Answering-based method to recognize entities and extract relationships. Our method has demonstrated robustness in handling diverse relationship patterns, and it remains effective even when trained on a low-resource dataset.","A"
P16,Revisiting Machine-Learning based Drug Repurposing: Drug Indications Are Not a Right Prediction Target,"Siun Kim* (Seoul National University)|Jung-Hyun Won (Seoul National University)|David Seung U Lee (Seoul National University)|Renqian Luo (Microsoft Research)|Lijun Wu (Microsoft Research)|Yingce Xia (Microsoft Research)|Tao Qin (Microsoft Research)|Howard Lee (Seoul National University)","In this paper, we challenge the utility of approved drug indications as a prediction target for machine learning in drug repurposing (DR) studies. Our research highlights two major limitations of this approach: 1) the presence of strong confounding between drug indications and drug characteristics data, which results in shortcut learning, and 2) inappropriate normalization of indications in existing drug-disease association (DDA) datasets, which leads to an overestimation of model performance. We show that the collection patterns of drug characteristics data were similar within drugs of the same category and the Anatomical Therapeutic Chemical (ATC) classification of drugs could be predicted by using the data collection patterns. Furthermore, we confirm that the performance of existing DR models is significantly degraded in the realistic evaluation setting we proposed in this study. We provide realistic data split information for two benchmark datasets, Fdataset and deepDR dataset.","A"
P17,Bayesian Active Questionnaire Design for Cause-of-Death Assignment Using Verbal Autopsies,"Toshiya Yoshida* (University of California Santa Cruz)|Trinity Shuxian Fan (University of Washington)|Tyler McCormick (University of Washington)|Zhenke Wu (University of Michigan)|Zehang Richard Li (University of California Santa Cruz)","Only about one-third of the deaths worldwide are assigned a medically-certified cause, and understanding the causes of deaths occurring outside of medical facilities is logistically and financially challenging. Verbal autopsy (VA) is a routinely used tool to collect information on cause of death in such settings. VA is a survey-based method where a structured questionnaire is conducted to family members or caregivers of a recently deceased person, and the collected information is used to infer the cause of death. As VA becomes an increasingly routine tool for cause-of-death data collection, the lengthy questionnaire has become a major challenge to the implementation and scale-up of VA interviews as they are costly and time-consuming to conduct. In this paper, we propose a novel active questionnaire design approach that optimizes the order of the questions dynamically to achieve accurate cause-of-death assignment with the smallest number of questions. We propose a fully Bayesian strategy for adaptive question selection that is compatible with any existing probabilistic cause-of-death assignment methods. We also develop an early stopping criterion that fully accounts for the uncertainty in the model parameters. We also propose a penalized score to account for constraints and preferences of existing question structures. We evaluate the performance of our active designs using both synthetic and real data, demonstrating that the proposed strategy achieves accurate cause-of-death assignment using considerably fewer questions than the traditional static VA survey instruments.","A"
P18,Machine Learning for Arterial Blood Pressure Prediction,"Jessica Zheng (MIT)|Hanrui Wang* (MIT)|Anand Chandrasekhar (MIT)|Aaron Aguirre (Massachusetts General Hospital and Harvard Medical School)|Song Han (MIT)|Hae-Seung Lee (MIT)|Charles G. Sodini (MIT)","High blood pressure is a major risk factor for cardiovascular disease, necessitating accurate blood pressure (BP) measurement. Clinicians measure BP with an invasive arterial catheter or via a non-invasive arm or finger cuff. However, the former can cause discomfort to the patient and is unsuitable outside Intensive Care Unit (ICU). While cuff-based devices, despite being non-invasive, fails to provide continuous measurement, and they measure from peripheral blood vessels whose BP waveforms differ significantly from those proximal to the heart. Hence, there is an urgent need to develop a measurement protocol for converting easily measured non-invasive data into accurate BP values. Addressing this gap, we propose a non-invasive approach to predict BP from arterial area and blood flow velocity signals measured from a Philips ultrasound transducer (XL-143) applied to large arteries close to heart. We developed the protocol and collected data from 72 subjects. The shape of BP (relative BP) can be theoretically calculated from these waveforms, however there is no established theory to obtain <span class=""font-italic"">absolute</span> BP values. To tackle this challenge, we further employ data-driven machine learning models to predict the Mean Arterial Blood Pressure (MAP), from which the absolute BP can be derived. Our study investigates various machine learning algorithms to optimize the prediction accuracy. We find that LSTM, Transformer, and 1D-CNN algorithms using the blood pressure shape and blood flow velocity waveforms as inputs can achieve 8.6, 8.7, and 8.8 mmHg average standard deviation of the prediction error respectively without anthropometric data such as age, sex, heart rate, height, weight. Furthermore, the 1D-CNN model can achieve 7.9mmHg when anthropometric data is added as inputs, improving upon an anthropometric-only model of 9.5mmHg. This machine learning-based approach, capable of converting ultrasound data into MAP values, presents a promising software tool for physicians in clinical decision-making regarding blood pressure management.","A"
P19,MultiWave: Multiresolution Deep Architectures through Wavelet Decomposition for Multivariate Time Series Prediction,"Iman Deznabi* (University of Massachusetts, Amherst)|Madalina Fiterau (University of Massachusetts, Amherst)","High blood pressure is a major risk factor for cardiovascular disease, necessitating accurate blood pressure (BP) measurement. Clinicians measure BP with an invasive arterial catheter or via a non-invasive arm or finger cuff. However, the former can cause discomfort to the patient and is unsuitable outside Intensive Care Unit (ICU). While cuff-based devices, despite being non-invasive, fails to provide continuous measurement, and they measure from peripheral blood vessels whose BP waveforms differ significantly from those proximal to the heart. Hence, there is an urgent need to develop a measurement protocol for converting easily measured non-invasive data into accurate BP values. Addressing this gap, we propose a non-invasive approach to predict BP from arterial area and blood flow velocity signals measured from a Philips ultrasound transducer (XL-143) applied to large arteries close to heart. We developed the protocol and collected data from 72 subjects. The shape of BP (relative BP) can be theoretically calculated from these waveforms, however there is no established theory to obtain <span class=""font-italic"">absolute</span> BP values. To tackle this challenge, we further employ data-driven machine learning models to predict the Mean Arterial Blood Pressure (MAP), from which the absolute BP can be derived. Our study investigates various machine learning algorithms to optimize the prediction accuracy. We find that LSTM, Transformer, and 1D-CNN algorithms using the blood pressure shape and blood flow velocity waveforms as inputs can achieve 8.6, 8.7, and 8.8 mmHg average standard deviation of the prediction error respectively without anthropometric data such as age, sex, heart rate, height, weight. Furthermore, the 1D-CNN model can achieve 7.9mmHg when anthropometric data is added as inputs, improving upon an anthropometric-only model of 9.5mmHg. This machine learning-based approach, capable of converting ultrasound data into MAP values, presents a promising software tool for physicians in clinical decision-making regarding blood pressure management.","B"
P20,Missing Values and Imputation in Healthcare Data: Can Interpretable Machine Learning Help?,"Zhi Chen* (Duke University)|Sarah Tan (Cornell University)|Urszula Chajewska (Microsoft Research)|Cynthia Rudin (Duke University)|Rich Caruana (Microsoft Research)","Missing values are a fundamental problem in data science. Many datasets have missing values that must be properly handled because the way missing values are treated can have large impact on the resulting machine learning model. In medical applications, the consequences may affect healthcare decisions. There are many methods in the literature for dealing with missing values, including state-of-the-art methods which often depend on black-box models for imputation. In this work, we show how recent advances in interpretable machine learning provide a new perspective for understanding and tackling the missing value problem. We propose methods based on high-accuracy glass-box Explainable Boosting Machines (EBMs) that can help users (1) gain new insights on missingness mechanisms and better understand the causes of missingness, and (2) detect -- or even alleviate -- potential risks introduced by imputation algorithms. Experiments on real-world medical datasets illustrate the effectiveness of the proposed methods.","B"
P21,Explaining a machine learning decision to physicians via counterfactuals,"Supriya Nagesh* (Amazon)|Nina Mishra (Amazon)|Yonatan Naamad (Amazon)|James M Rehg (Georgia Institute of Technology)|Mehul A Shah (Aryn)|Alexei Wagner (Harvard University)","Machine learning models perform well on several healthcare tasks and can help reduce the burden on the healthcare system. However, the lack of explainability is a major roadblock to their adoption in hospitals. <span class=""font-italic"">How can the decision of an ML model be explained to a physician?</span> The explanations considered in this paper are counterfactuals (CFs), hypothetical scenarios that would have resulted in the opposite outcome. Specifically, time-series CFs are investigated, inspired by the way physicians converse and reason out decisions `I would have given the patient a vasopressor if their blood pressure was lower and falling'. Key properties of CFs that are particularly meaningful in clinical settings are outlined: physiological plausibility, relevance to the task and sparse perturbations. Past work on CF generation does not satisfy these properties, specifically plausibility in that realistic time-series CFs are not generated. A variational autoencoder (VAE)-based approach is proposed that captures these desired properties. The method produces CFs that improve on prior approaches quantitatively (more plausible CFs as evaluated by their likelihood w.r.t original data distribution, and 100x faster at generating CFs) and qualitatively (2x more plausible and relevant) as evaluated by three physicians.","B"
P22,Leveraging an Alignment Set in Tackling Instance-Dependent Label Noise,"Donna Tjandra* (University of Michigan)|Jenna Wiens (University of Michigan)","Noisy training labels can hurt model performance. Most approaches that aim to address label noise assume label noise is independent from the input features. In practice, however, label noise is often feature or <span class=""font-italic"">instance-dependent</span>, and therefore biased (i.e., some instances are more likely to be mislabeled than others). E.g., in clinical care, female patients are more likely to be under-diagnosed for cardiovascular disease compared to male patients. Approaches that ignore this dependence can produce models with poor discriminative performance, and in many healthcare settings, can exacerbate issues around health disparities. In light of these limitations, we propose a two-stage approach to learn in the presence instance-dependent label noise. Our approach utilizes <span class=""font-italic"">alignment points</span>, a small subset of data for which we know the observed and ground truth labels. On several tasks, our approach leads to consistent improvements over the state-of-the-art in discriminative performance (AUROC) while mitigating bias (area under the equalized odds curve, AUEOC). For example, when predicting acute respiratory failure onset on the MIMIC-III dataset, our approach achieves a harmonic mean (AUROC and AUEOC) of 0.84 (SD [standard deviation] 0.01) while that of the next best baseline is 0.81 (SD 0.01).  Overall, our approach improves accuracy while mitigating potential bias compared to existing approaches in the presence of instance-dependent label noise.","A"
P23,Fair Admission Risk Prediction with Proportional Multicalibration,"William La Cava* (Boston Children's Hospital and Harvard Medical School)|Elle Lett (Boston Children's Hospital and Harvard Medical School)|Guangya Wan (Boston Children's Hospital and Harvard Medical School)","Fair calibration is a widely desirable fairness criteria in risk prediction contexts. One way to measure and achieve fair calibration is with multicalibration. Multicalibration constrains calibration error among flexibly-defined subpopulations while maintaining overall calibration. However, multicalibrated models can exhibit a higher percent calibration error among groups with lower base rates than groups with higher base rates. As a result, it is possible for a decision-maker to learn to trust or distrust model predictions for specific groups. To alleviate this, we propose <span class=""font-italic"">proportional multicalibration</span>, a criteria that constrains the percent calibration error among groups and within prediction bins. We prove that satisfying proportional multicalibration bounds a model's multicalibration as well its <span class=""font-italic"">differential calibration</span>, a fairness criteria that directly measures how closely a model approximates sufficiency. Therefore, proportionally calibrated models limit the ability of decision makers to distinguish between model performance on different patient groups, which may make the models more trustworthy in practice.  We provide an efficient algorithm for post-processing risk prediction models for proportional multicalibration and evaluate it empirically. We conduct simulation studies and investigate a real-world application of PMC-postprocessing to prediction of emergency department patient admissions. We observe that proportional multicalibration is a promising criteria for controlling simultaneous measures of calibration fairness of a model over intersectional groups with virtually no cost in terms of classification performance.","B"
P24,Collecting data when missingness is unknown: a method for improving model performance given under-reporting in patient populations,"Kevin Wu* (Stanford University and Optum Labs)|Dominik Dahlem (Optum Labs)|Christopher Hane (Optum Labs)|Eran Halperin (Optum Labs)|James Zou (Stanford University)","Machine learning models for healthcare commonly use binary indicator variables to represent the diagnosis of specific health conditions in medical records. However, in populations with significant under-reporting, the absence of a recorded diagnosis does not rule out the presence of a condition, making it difficult to distinguish between negative and missing values. This effect,  which we refer to as latent missingness, may lead to model degradation and perpetuate existing biases in healthcare. To address this issue, we propose that healthcare providers and payers  allocate a budget towards data collection (eg. subsidies for check-ups or lab tests). However, given finite resources, only a subset of data points can be collected. Additionally, most models are unable to be re-trained after deployment. In this paper, we propose a method for efficient data collection in order to maximize a fixed model's performance on a given population. Through simulated and real-world data, we demonstrate the potential value of targeted data collection to address model degradation.","A"
P25,Self-Supervised Pretraining and Transfer Learning Enable Flu and COVID-19 Predictions in Small Mobile Sensing Datasets,"Mike A Merrill* (University of Washington)|Tim Althoff (University of Washington)","Detailed mobile sensing data from phones and fitness trackers offer an opportunity to quantify previously unmeasurable behavioral changes to improve individual health and accelerate responses to emerging diseases. Unlike in natural language processing and computer vision, deep learning has yet to broadly impact this domain, in which the majority of research and clinical applications still rely on manually defined features or even forgo predictive modeling altogether due to insufficient accuracy. This is due to unique challenges in the behavioral health domain, including very small datasets (~10<sup>1</sup> participants), which frequently contain missing data, consist of long time series with critical long-range dependencies (length<10<sup>4</sup>), and extreme class imbalances (>10<sup>3</sup>:1). Here, we <span class=""font-italic"">describe</span> a neural architecture for multivariate time series classification designed to address these unique domain challenges. Our proposed behavioral representation learning approach combines novel tasks for self-supervised pretraining and transfer learning to address data scarcity, and captures long-range dependencies across long-history time series through transformer self-attention following convolutional neural network-based dimensionality reduction. We propose an evaluation framework aimed at reflecting expected real-world performance in plausible deployment scenarios. Concretely, we demonstrate (1) performance improvements over baselines of up to 0.15 ROC AUC across five influenza-related prediction tasks, (2) transfer learning-induced performance improvements <span class=""font-italic"">including a 16% relative increase</span> in PR AUC in small data scenarios, and (3) the potential of transfer learning in novel disease scenarios through an exploratory case study of zero-shot COVID-19 prediction in an independent data set.  Finally, we discuss potential implications for medical surveillance testing.","A"
P26,Clinical Relevance Score for Guided Trauma Injury Pattern Discovery with Weakly Supervised β-VAE,"Qixuan Jin* (Massachusetts Institute of Technology)|Jacobien Oosterhoff (Delft University of Technology)|Yepeng Huang (Harvard School of Public Health)|Marzyeh Ghassemi (Massachusetts Institute of Technology)|Gabriel A. Brat (Beth Israel Deaconess Medical Center and Harvard Medical School)","Given the complexity of trauma presentations, particularly in those involving multiple areas of the body, overlooked injuries are common during the initial assessment by a clinician. We are motivated to develop an automated trauma pattern discovery framework for comprehensive identification of injury patterns which may eventually support diagnostic decision-making. We analyze 1,162,399 patients from the Trauma Quality Improvement Program with a disentangled variational autoencoder, weakly supervised by a latent-space classifier of auxiliary features. We also develop a novel scoring metric that serves as a proxy for clinical intuition in extracting clusters with clinically meaningful injury patterns. We validate the extracted clusters with clinical experts, and explore the patient characteristics of selected groupings. Our metric is able to perform model selection and effectively filter clusters for clinically-validated relevance.","B"
P27,Evaluating Model Performance in Medical Datasets Over Time,"Helen Zhou* (Carnegie Mellon University)|Yuwen Chen (Carnegie Mellon University)|Zachary Chase Lipton (Carnegie Mellon University)","Machine learning (ML) models deployed in healthcare systems must face data drawn from continually evolving environments. However, researchers proposing such models typically evaluate them in a time-agnostic manner, splitting datasets according to patients sampled randomly throughout the entire study time period. This work proposes the Evaluation on Medical Datasets Over Time (EMDOT) framework, which evaluates the performance of a model class across time. Inspired by the concept of backtesting, EMDOT simulates possible training procedures that practitioners might have been able to execute at each point in time and evaluates the resulting models on all future time points. Evaluating both linear and more complex models on six distinct medical data sources (tabular and imaging), we show how depending on the dataset, using all historical data may be ideal in many cases, whereas using a window of the most recent data could be advantageous in others. In datasets where models suffer from sudden degradations in performance, we investigate plausible explanations for these shocks. We release the EMDOT package to help facilitate further works in deployment-oriented evaluation over time.","B"
P28,Rediscovery of CNN's Versatility for Text-based Encoding of Raw Electronic Health Records,"Eunbyeol Cho* (KAIST)|Min Jae Lee (KAIST)|Kyunghoon Hur (KAIST)|Jiyoun Kim (KAIST)|Jinsung Yoon (Google Cloud AI Research)|Edward Choi (KAIST)","Making the most use of abundant information in electronic health records (EHR) is rapidly becoming an important topic in the medical domain. Recent work presented a promising framework that embeds entire features in raw EHR data regardless of its form and medical code standards. The framework, however, only focuses on encoding EHR with minimal preprocessing and fails to consider how to learn efficient EHR representation in terms of computation and memory usage. In this paper, we search for a versatile encoder not only reducing the large data into a manageable size but also well preserving the core information of patients to perform diverse clinical tasks. We found that hierarchically structured Convolutional Neural Network (CNN) often outperforms the state-of-the-art model on diverse tasks such as reconstruction, prediction, and generation, even with fewer parameters and less training time. Moreover, it turns out that making use of the inherent hierarchy of EHR data can boost the performance of any kind of backbone models and clinical tasks performed. Through extensive experiments, we present concrete evidence to generalize our research findings into real-world practice. We give a clear guideline on building the encoder based on the research findings captured while exploring numerous settings.","A"
P29,Homekit2020: A Benchmark for Time Series Classification on a Large Mobile Sensing Dataset with Laboratory Tested Ground Truth of Influenza Infections,"Mike A Merrill (University of Washington)|Esteban Safranchik* (University of Washington)|Arinbjörn Kolbeinsson (Evidation Health)|Piyusha Gade (Evidation Health)|Ernesto Ramirez (Evidation Health)|Ludwig Schmidt (University of Washington)|Luca Foschini (Sage Bionetworks)|Tim Althoff (University of Washington)","Despite increased interest in wearables as tools for detecting various health conditions, there are not as of yet any large public benchmarks for such mobile sensing data. The few datasets that <span class=""font-italic"">are</span> available do not contain data from more than dozens of individuals, do not contain high-resolution raw data or do not include dataloaders for easy integration into machine learning pipelines. Here, we present Homekit2020: the first large-scale public benchmark for time series classification of wearable sensor data. Our dataset contains over 14 million hours of minute-level multimodal Fitbit data, symptom reports, and ground-truth laboratory PCR influenza test results, along with an evaluation framework that mimics realistic model deployments and efficiently characterizes statistical uncertainty in model selection in the presence of extreme class imbalance. Furthermore, we implement and evaluate nine neural and non-neural time series classification models on our benchmark across 450 total training runs in order to establish state of the art performance.","B"
P30,PTGB: Pre-Train Graph Neural Networks for Brain Network Analysis,"Yi Yang* (Emory University)|Hejie Cui (Emory University)|Carl Yang (Emory University)","The human brain is the central hub of the neurobiological system, controlling behavior and cognition in complex ways. Recent advances in neuroscience and neuroimaging analysis have shown a growing interest in the interactions between brain regions of interest (ROIs) and their impact on neural development and disorder diagnosis. As a powerful deep model for analyzing graph-structured data, Graph Neural Networks (GNNs) have been applied for brain network analysis. However, training deep models requires large amounts of labeled data, which is often scarce in brain network datasets due to the complexities of data acquisition and sharing restrictions. To make the most out of available training data, we propose PTGB, a GNN pre-training framework that captures intrinsic brain network structures, regardless of clinical outcomes, and is easily adaptable to various downstream tasks. PTGB comprises two key components: (1) an unsupervised pre-training technique designed specifically for brain networks, which enables learning from large-scale datasets without task-specific labels; (2) a data-driven parcellation atlas mapping pipeline that facilitates knowledge transfer across datasets with different ROI systems. Extensive evaluations using various GNN models have demonstrated the robust and superior performance of PTGB compared to baseline methods.","B"
P31,Do We Still Need Clinical Language Models?,"Eric Lehman* (MIT and Xyla)|Evan Hernandez (MIT and Xyla)|Diwakar Mahajan (IBM Research)|Jonas Wulff (Xyla)|Micah J. Smith (Xyla)|Zachary Ziegler (Xyla)|Daniel Nadler (Xyla)|Peter Szolovits (MIT)|Alistair Johnson (The Hospital for Sick Children)|Emily Alsentzer (Brigham and Women's Hospital and Harvard Medical School)","Although recent advances in scaling large language models (LLMs) have resulted in improvements on many NLP tasks, it remains unclear whether these models trained primarily with general web text are the right tool in highly specialized, safety critical domains such as <span class=""font-italic"">clinical text</span>. Recent results have suggested that LLMs encode a surprising amount of medical knowledge. This raises an important question regarding the utility of smaller domain-specific language models. With the success of general-domain LLMs, is there still a need for specialized clinical models? To investigate this question, we conduct an extensive empirical analysis of 12 language models, ranging from 220M to 175B parameters, measuring their performance on 3 different clinical tasks that test their ability to parse and reason over electronic health records. As part of our experiments, we train T5-Base and T5-Large models from scratch on clinical notes from MIMIC III and IV to directly investigate the efficiency of clinical tokens. We show that relatively small specialized clinical models substantially outperform all in-context learning approaches, even when finetuned on limited annotated data. Further, we find that pretraining on clinical tokens allows for smaller, more parameter-efficient models that either match or outperform much larger language models trained on general text. We release the code and the models used under the PhysioNet Credentialed Health Data license and data use agreement.","A"
P32,Contrastive Learning of Electrodermal Activity Representations for Stress Detection,"Katie Matton* (MIT CSAIL and MIT Media Lab)|Robert A Lewis* (MIT Media Lab)|John Guttag (MIT CSAIL)|Rosalind Picard (MIT Media Lab)","Electrodermal activity (EDA) is a biosignal that contains valuable information for monitoring health conditions related to sympathetic nervous system activity. Analyzing ambulatory EDA data is challenging because EDA measurements tend to be noisy and sparsely labeled. To address this problem, we present the first study of contrastive learning that examines approaches that are tailored to the EDA signal. We present a novel set of data augmentations that are tailored to EDA, and use them to generate positive examples for unsupervised contrastive learning. We evaluate our proposed approach on the downstream task of stress detection. We find that it outperforms baselines when used both for fine-tuning and for transfer learning, especially in regimes of high label sparsity. We verify that our novel EDA-specific augmentations add considerable value beyond those considered in prior work through a set of ablation experiments.","B"
P33,Understanding and Predicting the Effect of Environmental Factors on People with Type 2 Diabetes,"Kailas Vodrahalli* (Stanford University)|Gregory D. Lyng (Optum AI Labs)|Brian L. Hill (Optum AI Labs)|Kimmo Karkkainen (Optum AI Labs)|Jeffrey Hertzberg (Optum AI Labs)|James Zou (Stanford University)|Eran Halperin (Optum AI Labs)","Type 2 diabetes mellitus (T2D) affects over 530 million people globally and is often difficult to manage leading to serious health complications. Continuous glucose monitoring (CGM) can help people with T2D to monitor and manage the disease. CGM devices sample an individual's glucose level at frequent intervals enabling sophisticated characterization of an individual's health. In this work, we leverage a large dataset of CGM data (5,447 individuals and 940,663 days of data) paired with health records and activity data to investigate how glucose levels in people with T2D are affected by external factors like weather conditions, extreme weather events, and temporal events including local holidays. We find temperature (p=2.37x10<sup>-8</sup>, n=3561), holidays (p=2.23x10<sup>-46</sup>, n=4079), and weekends (p=7.64x10<sup>-124</sup>, n=5429) each have a significant effect on standard glycemic metrics at a population level. Moreover, we show that we can predict whether an individual will be significantly affected by a (potentially unobserved) external event using only demographic information and a few days of CGM and activity data. Using random forest classifiers, we can predict whether an individual will be more negatively affected than a typical individual with T2D by a given external factor with respect to a given glycemic metric. We find performance (measured as ROC-AUC) is consistently above chance (across classifiers, median ROC-AUC=0.63). Performance is highest for classifiers predicting the effect of time-in-range (median ROC-AUC=0.70). These are important findings because they may enable better patient care management with day-to-day risk assessments based on external factors as well as improve algorithm development by reducing train- and test-time bias due to external factors.","B"