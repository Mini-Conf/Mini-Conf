UID,title,authors,abstract,slideslive_id,rocketchat_id
ws1,"Differentially Private ""Small"" Dataset Release Using Random Projections",Lovedeep Gondara|Ke Wang,"Small datasets form a significant portion of releasable data in high sensitivity domains such as healthcare. But, providing differential privacy for small dataset release is a hard task, where current state-of-the-art methods suffer from severe utility loss. As a solution, we propose DPRP (Differentially Private Data Release via Random Projections), a reconstruction based approach for releasing differentially private small datasets. DPRP has several key advantages over the state-of-the-art. Using seven diverse real-life clinical datasets, we show that DPRP outperforms the current state-of-the-art on a variety of tasks, under varying conditions, and for all privacy budgets.",38931935,differentially_private_dataset
ws3,Learning Representations for Prediction of Next Patient State,Taylor Killian|Jayakumar Subramanian|Mehdi Fatemi|Marzyeh Ghassemi,"Reinforcement Learning (RL) has recently been applied to several problems in healthcare, with a particular focus in offline learning in observational data. RL relies on the use of latent states that embed sequential observations in such a way that the embedding is sufficient to approximately predict the next observation. but the appropriate construction of such states in healthcare settings is an open question, as the variation in steady-state human physiology is poorly-understood. In this work, we evaluate several information encoding schemes for offline RL using data from electronic health records (EHR). We use observations from septic patients in the MIMIC-III intensive care unit dataset, and evaluate the predictive performance of four embedding approaches in two tasks: predicting the next observation, and predicting a ``k-step'' look ahead or roll out. Our experiments highlight that the best performing state representation learning approaches utilize higher dimension recurrent neural architectures, and demonstrate that incorporating additional context with the state representation when predicting the next observation.",38931937,learning_representations_for_state
ws4,Deep State-Space Generative Model For Correlated Time-to-Event Predictions,Yuan Xue|Denny Zhou|Nan Du|Andrew M. Dai|Zhen Xu|Kun Zhang|Claire Cui,"Capturing the inter-dependencies among multiple types of clinically-critical events is critical not only to accurate future event prediction, but also to better treatment planning. In this work, we propose a deep latent state-space generative model to capture the interactions among different types of correlated clinical events (e.g., kidney failure, mortality) by explicitly modeling the temporal dynamics of patients' latent states. Based on these learned patient states, we further develop a new general discrete-time formulation of the hazard rate function to estimate the survival distribution of patients with significantly improved accuracy. Extensive evaluations over real EMR data show that our proposed model compares favorably to various state-of-the-art baselines. Further our method also uncovers meaningful insights about the latent correlation among mortality and different types of organ failures.",38931938,deep_state_space_gen
ws5,Differentially Private Survival Function Estimation,Lovedeep Gondara|Ke Wang,"Survival function estimation is used in many disciplines, but it is most common in medical analytics in the form of the Kaplan-Meier estimator. Sensitive data (patient records) is used in the estimation without any explicit control on the information leakage, which is a significant privacy concern. We propose a first differentially private estimator of the survival function and show that it can be easily extended to provide differentially private confidence intervals and test statistics without spending any extra privacy budget. We further provide extensions for differentially private estimation of the competing risk cumulative incidence function, Nelson-Aalen's estimator for the hazard function, etc. Using eleven real-life clinical datasets, we provide empirical evidence that our proposed method provides good utility while simultaneously providing strong privacy guarantees.",38931939,differentially_private_survival
ws7,Improving medical annotation quality to decrease labeling burden using stratified noisy cross-validation,Joy Hsu|Sonia Phene|Akinori Mitani|Jieying Luo|Naama Hammel|Jonathan Krause|Rory Sayres,"As machine learning has become increasingly applied to medical imaging data, noise in training labels has emerged as an important challenge. Variability in diagnosis of medical images is well established; in addition, variability in training and attention to task among medical labelers may exacerbate this issue. Methods for identifying and mitigating the impact of low quality labels have been studied, but are not well characterized in medical imaging tasks. For instance, Noisy Cross-Validation splits the training data into halves, and has been shown to identify low-quality labels in computer vision tasks; but it has not been applied to medical imaging tasks specifically. In addition, there may be concerns around label imbalance for medical image sets, where relevant pathology may be rare. In this work we introduce Stratified Noisy Cross-Validation (SNCV), an extension of noisy cross validation. SNCV allows us to measure confidence in model prediction and assign a quality score to each example; supports label stratification to handle class imbalance; and identifies likely low-quality labels to analyse the causes. In contrast to noisy cross-validation, sample selection for SNCV occurs after training two models, not during training, which simplifies application of the method. We assess performance of SNCV on diagnosis of glaucoma suspect risk (GSR) from retinal fundus photographs, a clinically important yet nuanced labeling task. Using training data from a previously-published deep learning model, we compute a continuous quality score (QS) for each training example. We relabel 1,277 low-QS examples using a trained glaucoma specialist; the new labels agree with the SNCV prediction over the initial label >85% of the time, indicating that low-QS examples appear mostly reflect labeler erors. We then quantify the impact of training with only high-QS labels, showing that strong model performance may be obtained with many fewer examples. By applying the method to randomly sub-sampled training dataset, we show that our method can reduce labelling burden by approximately 50% while achieving model performance non-inferior to using the full dataset on multiple held-out test sets.",38931941,improving_medical_annotation
ws8,A Multi-Task Learning Approach to Personalized Progression Modeling,Mohamed Ghalwash|Daby Sow,"Modeling disease progression is an active area of research. Many computational methods for progression modeling have been developed but mostly at population levels. In this paper, we formulate a personalized disease progression modeling problem as a multi-task regression problem where the estimation of progression scores at different time points is defined as a learning task. We introduce a  Personalized Progression Modeling (PPM) scheme as a novel way to estimate personalized trajectories of disease by jointly discovering clusters of similar patients while estimating disease progression scores. The approach is formulated as an optimization problem that can be solved using existing optimization techniques. We present efficient algorithms for the PPM scheme, together with experimental results on both synthetic and real world healthcare data proving its analytical efficacy over other 4 baseline methods representing the current state of the art. On synthetic data, we showed that our algorithm achieves over 40% accuracy improvement over all the baselines. On the healthcare application PPM has a 4% accuracy improvement on average over the state-of-the-art baseline in predicting the viral infection progression. These results highlight significant modeling performance gains obtained with PPM.",38931942,multitask_learning_personalized
ws9,Improved Patient Classification with Hierarchical Language Model Pretraining over Clinical Notes,Jonas Kemp|Alvin Rajkomar|Andrew M. Dai,"Clinical notes in electronic health records contain highly heterogeneous writing styles, including non-standard terminology or abbreviations. Using these notes in predictive modeling has traditionally required preprocessing (e.g. taking frequent terms or topic modeling) that removes much of the richness of the source data. We propose a pretrained hierarchical recurrent neural network model that parses minimally processed clinical notes in an intuitive fashion, and show that it improves performance for discharge diagnosis classification tasks on the Medical Information Mart for Intensive Care III (MIMIC-III) dataset, compared to models that conduct no pretraining or that treat the notes as an unordered collection of terms. We also apply an attribution technique to examples to identify the words that the model uses to make its prediction, and show the importance of the wordsâ€™ nearby context.",38931943,improved_patient_classification
ws10,Health change detection using temporal transductive learning,Abhay Harpale,"Industrial equipment, devices and patients typically undergo change from a healthy state to an unhealthy state. We develop a novel approach to detect unhealthy entities and also discover the time of change to enable deeper investigation into the cause for change. In the absence of an engineering or medical intervention, health degradation only happens in one direction --- healthy to unhealthy. Our transductive learning framework leverages this chronology of observations for learning a superior model with minimal supervision. Temporal Transduction is achieved by incorporating chronological constraints in the conventional max-margin classifier --- Support Vector Machines (SVM). We utilize stochastic gradient descent to solve the resulting optimization problem. Our experiments on publicly available benchmark datasets demonstrate the effectiveness of our approach in accurately detecting unhealthy entities with less supervision as compared to other strong baselines --- conventional and transductive SVM.",38931944,health_change_detection
ws11,Cost-Sensitive Feature Selection Using Bayesian Optimization,Lucca G. Zenobio|Thiago N. C. Cardoso|Andrea Kauffmann|Augusto Antunes,"In many Machine Learning applications, it is important to reduce the set of features used in training. This is especially important when different attributes have different acquisition costs, e.g., various blood tests. Cost-sensitive feature selection methods aim to select a subset of attributes that yields a performant Machine Learning model while keeping the total cost low. In this paper, we propose a Bayesian Optimization approach to this task. We explore the different subsets of available features by optimizing an evaluation function that weights the model's performance and total feature cost. We evaluate the proposed method on different UCI datasets, as well as a real-life one, and compare it to diverse feature selection approaches. Our results demonstrate that the Bayesian optimization cost-sensitive feature selection (BOCFS) can select a low-cost subset of informative features, therefore generating highly effective classifiers, and achieving state-of-the-art performance in some datasets.",38931945,cost_sensitive_feature
ws12,A large-scale Twitter dataset for drug safety applications mined from publicly existing resources,Ramya Tekumalla|Juan M Banda,"With the increase in popularity of deep learning models for natural language processing (NLP) tasks in the field of Pharmacovigilance, more specifically for the identification of Adverse Drug Reactions (ADRs), there is an inherent need for large-scale social-media datasets aimed at such tasks. With most researchers allocating large amounts of time to crawl Twitter or buying expensive pre-curated datasets, then manually annotating by humans, these approaches do not scale well as more and more data keeps flowing in Twitter. In this work we re-purpose a publicly available archived dataset of more than 9.4 billion Tweets with the objective of creating a very large dataset of drug usage-related tweets. Using existing manually curated datasets from the literature, we then validate our filtered tweets for relevance using machine learning methods, with the end result of a publicly available dataset of 1,181,993 million tweets for public use. We provide all code and detailed procedure on how to extract this dataset and the selected tweet ids for researchers to use.",38931946,twitter_dataset_drug_safety
ws13,ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission,Kexin Huang|Jaan Altosaar|Rajesh Ranganath,"Clinical notes contain information about patients beyond structured data such as lab values or medications. However, clinical notes have been underused relative to structured data, because notes are high-dimensional and sparse. We aim to develop and evaluate a continuous representation of clinical notes. Given this representation, our goal is to predict 30-day hospital readmission at various timepoints of admission, including early stages and at discharge. We apply bidirectional encoder representations from transformers (BERT) to clinical text. Publicly-released BERT parameters are trained on standard corpora such as Wikipedia and BookCorpus, which differ from clinical text. We therefore pre-train BERT using clinical notes and fine-tune the network for the task of predicting hospital readmission. This defines ClinicalBERT. ClinicalBERT uncovers high-quality relationships between medical concepts, as judged by physicians. ClinicalBERT outperforms various baselines on 30-day hospital readmission prediction using both discharge summaries and the first few days of notes in the intensive care unit on various clinically-motivated metrics. The attention weights of ClinicalBERT can also be used to interpret predictions. To facilitate research, we open-source model parameters, and scripts for training and evaluation. ClinicalBERT is a flexible framework to represent clinical notes. It improves on previous clinical text processing methods and with little engineering can be adapted to other clinical predictive tasks.",38931947,clinical_bert
ws14,Mining Dynamic Problem Lists from Clinical Notes for the Interpretable Prediction of Adverse Outcomes,Justin Lovelace|Nathan Hurley|Adrian Haimovich|Bobak Mortazavi,"Problem lists are intended to provide clinicians with a relevant summary of patient medical issues and are embedded in many electronic health record systems. Despite their importance, problem lists are often cluttered with resolved or currently irrelevant conditions. In this work, we develop a novel end-to-end framework to first extract problem lists from clinical notes and subsequently use the extracted problems to predict patient outcomes. This framework is both more performant and more interpretable than existing models used within the domain, achieving an AU-ROC of 0.710 for bounceback readmission and 0.869 for in-hospital mortality occurring after ICU discharge. We identify risk factors for both readmission and mortality outcomes and demonstrate that it can be used to develop dynamic problem lists that present clinical problems along with their quantitative importance. This allows clinicians to both easily identify the relevant problems and gain insight into the factors driving the modelâ€™s prediction.",38931948,mining_dynamic_problem
ws15,Deep Transfer Learning for Physiological Signals,Hugh Chen|Scott Lundberg|Gabe Erion|Jerry H. Kim|Su-In Lee,"Deep learning is increasingly common in healthcare, yet transfer learning for physiological signals (e.g., temperature, heart rate, etc.) is under-explored. Here, we present a straightforward, yet performant framework for transferring knowledge about physiological signals. Our framework is called PHASE (\underline{PH}ysiologic\underline{A}l \underline{S}ignal \underline{E}mbeddings). It i) learns deep embeddings of physiological signals and ii) predicts adverse outcomes based on the embeddings. PHASE is the first instance of deep transfer learning in a cross-hospital, cross-department setting for physiological signals. We show that PHASE's per-signal (one for each signal) LSTM embedding functions confer a number of benefits including improved performance, successful transference between hospitals, and lower computational cost.",38931949,deep_transfer_learning
ws16,Open Set Medical Diagnosis,Viraj Prabhu|Anitha Kannan|Geoffrey J. Tso|Namit Katariya|Manish Chablani|David Sontag|Xavier Amatriain,"Machine-learned diagnosis models have shown promise as medical aides but are trained under a closed-set assumption, i.e. that models will only encounter conditions on which they have been trained. However, it is practically infeasible to obtain sufficient training data for every human condition, and once deployed such models will invariably face previously unseen conditions. We frame machine-learned diagnosis as an open-set learning problem, and study how state-of-the-art approaches compare. Further, we extend our study to a setting where training data is distributed across several healthcare sites that do not allow data pooling, and experiment with different strategies of building open-set diagnostic ensembles. Across both settings, we observe consistent gains from explicitly modeling unseen conditions, but find the optimal training strategy to vary across settings.",38931950,open_set_medical_diagnosis
ws17,Assessing Robustness of Deep Learning Methods in Dermatological Workflow,Sourav Mishra|Subhajit Chaudhury|Hideaki Imaizumi|Toshihiko Yamasaki,"This paper aims to evaluate the suitability of current deep learning methods for clinical workflow especially by focusing on dermatology. Although deep learning methods have been attempted to  get dermatologist level accuracy in several individual conditions, it has not been rigorously tested for common clinical complaints. Most projects involve data acquired in well-controlled laboratory  conditions. This may not reflect regular clinical evaluation where corresponding image quality is not always ideal. We test the robustness of deep learning methods by simulating non-ideal characteristics on user submitted images of ten classes of diseases. Assessing via imitated  conditions, we have found the overall accuracy to drop and individual predictions change significantly in many cases despite of robust training.",38931951,assessing_robustness_dermatology
ws20,Automated Emotional Valence Prediction in Mental Health Text via Deep Transfer Learning,Benjamin Shickel|Martin Heesacker|Sherry Benton|Parisa Rashidi,"Sentiment analysis is a well-researched field of machine learning and natural language processing generally concerned with determining the degree of positive or negative polarity in free text. Traditionally, such methods have focused on analyzing user opinions directed towards external entities such as products, news, or movies. However, less attention has been paid towards understanding the sentiment of human emotion in the form of internalized thoughts and expressions of self-reflection. Given the rise of public social media platforms and private online therapy services, the opportunity for designing accurate tools to quantify emotional states in is at an all-time high. Based upon findings in psychological research, in this work we propose a new type of sentiment analysis task more appropriate for assessing the valence of human emotion. Rather than assessing text on a single polarity axis ranging from positive to negative, we analyze self-expressive thoughts using a two-dimensional assignment scheme with four sentiment categories: positive, negative, both positive and negative, and neither positive nor negative. This work details the collection of a novel annotated dataset of real-world mental health therapy logs and compares several machine learning methodologies for the accurate classification of emotional valence. We found superior performance using deep transfer learning approaches, and in particular, best results were obtained using the recent breakthrough method of BERT (Bidirectional Encoder Representations from Transformers). Based on these results, it is clear that transfer learning has the potential for greatly improving the accuracy of classifiers in the mental health domain, where labeled data is often scarce. Additionally, we argue that representing emotional sentiment on decoupled valence axes via four classification labels is an appropriate modification of traditional sentiment analysis for mental health tasks.",38931954,automated_emotional_valence
ws21,Generation of Differentially Private Heterogeneous Synthetic Electronic Health Records using GANs,Kieran Chin-Cheong|Thomas M. Sutter|Julia E. Vogt,"Electronic Health Records (EHRs) are commonly used by the machine learning community for research on problems specifically related to health care and medicine. EHRs have the advantages that they can be easily distributed and contain many features useful for e.g. classification problems. What makes EHR data sets different from typical machine learning data sets is that they are often very sparse, due to their high dimensionality, and often contain heterogeneous data types. Furthermore, the data sets deal with sensitive information, which limits the distribution of any models learned using them, due to privacy concerns. In this work, we explore using Generative Adversarial Networks to generate synthetic, heterogeneous EHRs with the goal of using these synthetic records in place of existing data sets. We will further explore applying differential privacy (DP) preserving optimization in order to produce differentially private synthetic EHR data sets, which provide rigorous privacy guarantees, and are therefore more easily shareable. The performance (measured by AUROC, AUPRC and accuracy) of our model's synthetic, heterogeneous data is very close to the original data set (within 6.4%) for the non-DP model when tested in a binary classification task. Although incurring a 20% performance penalty, the DP synthetic data is still useful for machine learning tasks. We additionally perform a sub-population analysis and find that our model does not introduce any bias into the synthetic EHR data compared to the baseline in either male/female populations, or the 0-18, 19-50 and 51+ age groups in terms of classification performance.",38931955,generation_differentially_private
ws22,Integrating Physiological Time Series and Clinical Notes with Deep Learning for Improved ICU Mortality Prediction,Satya Narayan Shukla|Benjamin Marlin,"Intensive Care Unit Electronic Health Records (ICU EHRs) store multimodal data about patients including clinical notes, sparse and irregularly sampled physiological time series, lab results, and more. To date, most methods designed to learn predictive models from ICU EHR data have focused on a single modality. In this paper, we leverage the recently proposed interpolation-prediction deep learning architecture as a basis for exploring how physiological time series data and clinical notes can be integrated into a unified mortality prediction model. We study both early and late fusion approaches, and demonstrate how the relative predictive value of clinical text and physiological data change over time. Our results show that a late fusion approach can provide a statistically significant improvement in mortality prediction performance over using individual modalities in isolation.",38931956,integrating_physiological_time
ws23,CheXpedition: Investigating Generalization Challenges for Translation of Chest X-Ray Algorithms to the Clinical Setting,Pranav Rajpurkar|Anirudh Joshi|Phil Chen|Anuj Pareek|Amir Kiani|Matthew Lungren|Andrew Ng|Jeremy Irvin,"Although there have been several recent advances in the application of deep learning algorithms to chest x-ray interpretation, we identify three major challenges for the translation of chest x-ray algorithms to the clinical setting. We examine the performance of the top 10 performing models on the CheXpert challenge leaderboard on three tasks: (1) TB detection, (2) pathology detection on photos of chest x-rays, and (3) pathology detection on data from an external institution. First, we find that the top 10 chest x-ray models on the CheXpert competition achieve an average AUC of 0.851 on the task of detecting TB on two public TB datasets without fine-tuning or including the TB labels in training data. Second, we find that the average performance of the models on photos of x-rays (AUC = 0.916) is similar to their performance on the original chest x-ray images (AUC = 0.924). Third, we find that the models tested on an external dataset either perform comparably to or exceed the average performance of radiologists. We believe that our investigation will inform rapid translation of deep learning algorithms to safe and effective clinical decision support tools that can be validated prospectively with large impact studies and clinical trials.",38931957,chexpedition_investigating_generalization
ws24,Automated Medical Coding using BERT: Benchmarking Deep Learning in the Face of Subjective Labels,Mehmet Seflek|Wesam Elshamy|Abboud Chaballout|Ali Madani,"Documenting patients' interactions with health providers and institutions requires summarizing highly complex data. Medical coding reduces the dimensionality of this problem to a set of manually assigned codes that are used to bill, track patient health, and summarize a patient encounter. Incorrect coding, however, can lead to significant financial, legal, and health costs to clinics and patients. To address this, we build several deep learning models -- including transfer learning of state-of-the-art BERT models -- to predict medical codes on a novel dataset of 39,000 patient encounters. We also show through several labeling experiments that model performance is robust to subjectivity in the labels, and find that our models outperform a clinic's coding when judged against charts corrected and relabeled by an expert.",38931958,automated_medical_coding
ws25,Distracted Multi-task Learning: Addressing Negative Transfer with Fine-tuning on EHR Time-series Data,Matthew McDermott|Bret Nestor|Wancong Zhang|Peter Szolovits|Anna Goldenberg|Marzyeh Ghassemi,"Representation learning is a commonly touted goal in machine learning for healthcare, and for good reason. If we could learn a numerical encoding of clinical data which is reflective of underlying physiological similarity, this would have significant benefits both in research and application. However, many works pursuing representation learning systems evaluate only according to traditional, single-task performance metrics, and fail to assess whether or not the representations they produce actually contain generalizable signals capturing this underlying notion of similarity. In this work, we design an evaluation procedure specifically for representation learning systems, and use it to analyze the value of large-scale multi-task representation learners. We find mixed results, with multi-task representations being commonly helpful across a battery of prediction tasks and models, even while ensemble performance is often improvement by removing tasks from the trained ensemble and learned representations demonstrate no ability to cluster.",38931959,a_comprehensive_evaluation
ws26,Dataset Bias in Diagnostic AI systems: Guidelines for Dataset Collection and Usage,Julie R Vaughn|Avital Baral|Mayukha Vadari|William Boag,"In the last few years, the FDA has begun to recognize De Novo pathways (new approval processes) for approving AI as medical devices. A major concern with this is that the review process does not adequately test for biases in these models. There are many ways in which biases can arise in data, including during data collection, training, and model deployment. In this paper, we adopt a framework for categorizing the types of bias in datasets in a fine-grained way, which enables informed, targeted interventions for each issue appropriately. From there, we propose policy recommendations to the FDA and NIH to promote the deployment of more equitable AI diagnostic systems.",38931960,dataset_bias_in_diagnostic
ws27,Temporal-Clustering Invariance in Irregular Healthcare Time Series,Mohammad Taha Bahadori|Zachary Lipton,"Electronic records contain sequences of events, some of which take place all at once in a single visit, and others that are dispersed over multiple visits, each with a different timestamp. We postulate that fine temporal detail, e.g., whether a series of blood tests  are completed at once or in rapid succession should not alter predictions based on this data.  Motivated by this intuition, we propose models for analyzing sequences of multivariate clinical time series data that are invariant to this temporal clustering. We propose an efficient data augmentation technique that exploits the postulated temporal-clustering invariance to regularize deep neural networks optimized for several clinical prediction tasks.  We introduce two techniques to temporally coarsen (downsample) irregular time series:  (i) grouping the data points based on regularly-spaced timestamps;  and (ii) clustering them, yielding irregularly-paced timestamps.  Moreover, we propose a MultiResolution network with Shared Weights (MRSW), improving predictive accuracy by combining predictions  based on inputs sequences transformed by different coarsening operators. Our experiments show that MRSW improves the mAP on the benchmark mortality prediction task from 51.53% to 53.92%.",38931987,temporal_clustering_invariance
ws28,Calibrated Deep Nonparametric Survival Analysis,Fahad Kamran|Jenna Wiens,"In survival analysis, deep learning approaches have recently been proposed for estimating an individual's probability of survival over some time horizon. Such approaches can capture complex non-linear relationships, without relying on restrictive assumptions regarding the specific form of the relationship between an individual's characteristics and their underlying survival process. To date, however, these methods have focused primarily on optimizing discriminative performance, and have ignored model calibration. Well-calibrated survival curves present realistic and meaningful probabilistic estimates of the true underlying survival process for an individual. However, due to the lack of ground-truth regarding the underlying stochastic process of survival for an individual, optimizing for and measuring calibration in survival analysis is an inherently difficult task. In this work, we i) propose a new loss function, for training deep nonparametric survival analysis models, that maximizes discriminative performance, subject to good calibration, and ii) present a calibration metric for survival analysis that facilitates model comparison. Through experiments on two publicly available clinical datasets, we show that our proposed approach achieves the same discriminative performance as state-of-the-art methods, while leading to over a 60% reduction in calibration error.",38931988,calibrated_deep_nonparametric
