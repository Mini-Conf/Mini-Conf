## <center> Impact and Society:<br /> Policy, Public Health, and Social Outcomes </center>



<!-- ### Description -->
Algorithms do not exist in a vacuum: instead, they often explicitly aim for important social outcomes. This track considers issues at the intersection of algorithms and the societies they seek to impact, specifically for health. Submissions could include methodological contributions such as algorithmic development and performance evaluation for policy and public health applications, large-scale or challenging data collection, combining clinical and non-clinical data, as well as detecting and measuring bias. Submissions could also include impact-oriented research such as determining how algorithmic systems for health may introduce, exacerbate, or reduce inequities and inequalities, discrimination, and unjust outcomes, as well as evaluating the economic implications of these systems. We invite submissions tackling the responsible design of AI applications for healthcare and public health. System design for the implementation of such applications at scale is also welcome, which often requires balancing various tradeoffs in decision-making. Submissions related to understanding barriers to the deployment and adoption of algorithmic systems for societal-level health applications are also of interest. In addressing these problems, insights from social sciences, law, clinical medicine, and the humanities can be crucial.



**Examples**
<!-- Bolukbasi, Tolga, et al. "Quantifying and reducing stereotypes in word embeddings." arXiv preprint arXiv:1606.06121 (2016). -->

Obermeyer, Ziad, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. "<a href="https://www.science.org/doi/pdf/10.1126/science.aax2342?casa_token=ktlwGAIuojUAAAAA:Fpc6CxiJJ5ju1lPAKXcVN3b6K__8YNLo3B6SAg53ukz3a1IeumxD_SMEOxgGLhcRflqg46DO1KZsEg" target="_blank" rel="noopener">Dissecting racial bias in an algorithm used to manage the health of populations.</a>" Science 366.6464 (2019): 447-453.

<!-- Kleinberg, Jon, and Sendhil Mullainathan. "Simplicity creates inequity: implications for fairness, stereotypes, and interpretability." Proceedings of the 2019 ACM Conference on Economics and Computation. 2019. -->

Zink, Anna, and Sherri Rose. "<a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13206" target="_blank" rel="noopener">Fair regression for health care spending.</a>" Biometrics 76.3 (2020): 973-982.

Yang, Wanqian, Lars Lorch, Moritz Graule, Himabindu Lakkaraju, and Finale Doshi-Velez. "<a href="https://proceedings.neurips.cc/paper/2020/file/95c7dfc5538e1ce71301cf92a9a96bd0-Paper.pdf" target="_blank" rel="noopener">Incorporating interpretable output constraints in Bayesian neural networks.<a>" Advances in Neural Information Processing Systems 33 (2020): 12721-12731.

<!-- Bhatt, Umang, et al. "Explainable machine learning in deployment." Proceedings of the 2020 conference on fairness, accountability, and transparency. 2020. -->

Pierson, Emma, David M. Cutler, Jure Leskovec, Sendhil Mullainathan, and Ziad Obermeyer. "<a href="https://idp.nature.com/authorize/casa?redirect_uri=https://www.nature.com/articles/s41591-020-01192-7&casa_token=PN3YtykvC64AAAAA:Ky5Xhvl3n-AdGTr_O47GKeob9UrgH1miWOsHqumi7C7vvQx89hx22QpBePSGhVdGH0GTKejQ3drIcBen" target="_blank" rel="noopener">An algorithmic approach to reducing unexplained pain disparities in underserved populations.<a>" Nature Medicine 27.1 (2021): 136-140.

Seyyed-Kalantari, Laleh, Haoran Zhang, Matthew BA McDermott, Irene Y. Chen, and Marzyeh Ghassemi. "<a href="https://www.nature.com/articles/s41591-021-01595-0" target="_blank" rel="noopener">Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations.<a>" Nature medicine 27.12 (2021): 2176-2182.

<!-- Panch, Trishan, Heather Mattie, and Leo Anthony Celi. "The “inconvenient truth” about AI in healthcare." NPJ digital medicine 2.1 (2019): 1-3. -->
